{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc3c8b2-35fb-44c3-800e-ef9bc13a9231",
   "metadata": {},
   "source": [
    "# Decoding CTC output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d378ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq editdistance tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b923207-7a92-47f3-9f8f-1448b2ba4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "# Load precomputed CTC output\n",
    "with open('mystery_records.pickle', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
    "log_probs = batch[\"log_probs\"]\n",
    "\n",
    "# Dictionary with index to character mapping\n",
    "ind2char = batch[\"ind2char\"]\n",
    "\n",
    "# Index of special EMPTY token\n",
    "EMPTY_TOK = '^'\n",
    "EMPTY_IND = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fada795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 655, 28]), 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.size(), len(ind2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a12a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '^',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 27: ' '}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922cbf65-fbaf-48d5-8605-ea41c3f80590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) we nostrngesto love you know therols and so do i a foll commitment what i thinking of you wolden get this from any ather guy\n",
      "1)  never gona give you up never donelet you down never go arun around and deset you never gon a make you cri never gonna say good by\n"
     ]
    }
   ],
   "source": [
    "def ctc_decode(inds, ind2char):\n",
    "    decoded = []\n",
    "    last_chat_ind = EMPTY_IND\n",
    "    \n",
    "    for ind in inds:\n",
    "        if last_chat_ind == ind:\n",
    "            continue\n",
    "        elif ind != EMPTY_IND:\n",
    "            decoded.append(ind2char[ind])\n",
    "            \n",
    "        last_chat_ind = ind\n",
    "    \n",
    "    return ''.join(decoded)\n",
    "\n",
    "for i, rec in enumerate(log_probs):\n",
    "    text = ctc_decode(rec.argmax(-1).numpy(), ind2char)\n",
    "    print(f\"{i}) {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c4d50-e633-4e85-8842-a6b50602b70f",
   "metadata": {},
   "source": [
    "# Computing WER and CER\n",
    "Task: Implemet WER and CER metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca11f70-ee02-4765-b542-96186781a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for fast quick calculation of edit distance\n",
    "import editdistance\n",
    "\n",
    "def calc_wer(target_text: str, pred_text: str):\n",
    "    if len(target_text) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    target_text_split = target_text.split()\n",
    "    return editdistance.eval(target_text_split, pred_text.split()) / len(target_text_split)\n",
    "    \n",
    "\n",
    "def calc_cer(target_text: str, pred_text: str):\n",
    "    if len(target_text) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    return editdistance.eval(target_text, pred_text) / len(target_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c391511-7469-4ed8-bd26-057c4fde4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for target, pred, expected_wer, expected_cer in [\n",
    "    (\"if you can not measure it you can not improve it\", \n",
    "     \"if you can nt measure t yo can not i\", \n",
    "     0.454, 0.25),\n",
    "    (\"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     \"if you cant describe what you are doing as a process you dont know what youre doing\", \n",
    "     0.0, 0.0),\n",
    "    (\"one measurement is worth a thousand expert opinions\", \n",
    "     \"one  is worth thousand opinions\", \n",
    "     0.375, 0.392)\n",
    "]:\n",
    "    wer = calc_wer(target, pred)\n",
    "    cer = calc_cer(target, pred)\n",
    "    assert np.isclose(wer, expected_wer, atol=1e-3), f\"true: {target}, pred: {pred}, expected wer {expected_wer} != your wer {wer}\"\n",
    "    assert np.isclose(cer, expected_cer, atol=1e-3), f\"true: {target}, pred: {pred}, expected cer {expected_cer} != your cer {cer}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefd76b-66d4-4b1e-ae1d-be6b7336a160",
   "metadata": {},
   "source": [
    "Task: come up with such a pair of target-prediction texts, so the\n",
    "1) WER > 1.0\n",
    "2) CER > WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11bceaaf-7b17-466b-ac17-855e4d54cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) WER > 1.0\n",
    "# your code here\n",
    "target, prediction = \"a\" , \"a a a a a a\"\n",
    "assert calc_wer(target, prediction) > 1.0\n",
    "\n",
    "# 2) CER > WER\n",
    "# your code here\n",
    "target, prediction = \"a a a\", \"bbbbb a a\"\n",
    "assert calc_wer(target, prediction) < calc_cer(target, prediction) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1fb97-4853-4190-835d-31ead094679c",
   "metadata": {},
   "source": [
    "# Beam search\n",
    "Task: implement beam-search on CTC outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8e1c37a-93be-47a1-8211-9b47d0721d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed CTC output\n",
    "with open('lj_batch.pickle', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
    "log_probs = batch[\"log_probs\"]\n",
    "\n",
    "# Dictionary with index to character mapping\n",
    "ind2char = batch[\"ind2char\"]\n",
    "\n",
    "true_texts = batch[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0b65ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '^',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 27: ' '}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18103a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 310, 28]), 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.size(), len(ind2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30a6b8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he would go to her and tell her all his family complications',\n",
       " 'he did not say the last as a boast but merely as an assurance to the liveryman who he saw was anxious on his account',\n",
       " 'he started to conscious confusion only neither knowing where he was nor what he did',\n",
       " \"i'm here because the matter is of utmost importance and brandd is the one i must see now stand aside\",\n",
       " \"of course it ain't said missus bozzle\",\n",
       " 'mister verloc was fully responsive now',\n",
       " 'oh what shall we do for a home',\n",
       " \"line of battle was formed on the north bank of stone's river on the yankee side\",\n",
       " 'from fifteen to twenty minutes will be required to bake them nicely',\n",
       " 'whom is he going to flog now']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6caa067",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = log_probs.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ae1f264-33cb-4c4d-b959-823d07843936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def expand_and_merge_path(dp, next_token_probs, ind2char):\n",
    "    new_dp = defaultdict(float)\n",
    "    \n",
    "    for idx, next_token_prob in enumerate(next_token_probs):\n",
    "        curr_char = ind2char[idx]\n",
    "        new_prefix = \"\"\n",
    "        for (prefix, last_char), v in dp.items():\n",
    "            if last_char == curr_char:\n",
    "                new_prefix = prefix\n",
    "            else:\n",
    "                if curr_char != EMPTY_TOK:\n",
    "                    new_prefix = prefix + curr_char\n",
    "                else:\n",
    "                    new_prefix = prefix\n",
    "            new_dp[(new_prefix, curr_char)] += v * next_token_prob\n",
    "                \n",
    "            \n",
    "    return new_dp\n",
    "\n",
    "def truncate_paths(dp, beam_size):\n",
    "    return dict(sorted(list(dp.items()), key=lambda x: -x[1])[:beam_size])\n",
    "\n",
    "\n",
    "def ctc_beam_search(probs, beam_size, ind2char):\n",
    "    dp = {\n",
    "        (\"\", EMPTY_TOK): 1.0\n",
    "    }\n",
    "    \n",
    "    for prob in probs:\n",
    "        dp = expand_and_merge_path(dp, prob, ind2char)\n",
    "        dp = truncate_paths(dp, beam_size)\n",
    "        \n",
    "    dp = [(prefix, prob) for (prefix, _), prob in sorted(dp.items(), key=lambda x: -x[1])]\n",
    "    return dp\n",
    "\n",
    "bs_results = []\n",
    "for log_probs_line in log_probs:\n",
    "    bs_results.append(ctc_beam_search(log_probs_line.exp().numpy(), 100, ind2char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e6d7249-aed1-4ff3-8ce2-20978320ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  he would go to her and tell her all his family complications\n",
      "Argmax: he wld ge toher iand tell her all mhisan ly omblications --- (CER: 0.200)\n",
      "1) 'he wl ge to her iand tell her all hisan ly omblications' --- (CER: 0.183)\n",
      "2) 'he wl ge to her and tell her all hisan ly omblications' --- (CER: 0.167)\n",
      "3) 'he wl ge to her iand tell her all hisanly omblications' --- (CER: 0.183)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  he did not say the last as a boast but merely as an assurance to the liveryman who he saw was anxious on his account\n",
      "Argmax: he did not sad the last is a bost but mearlioves an asurance to the livery man who re saw was anxes on his account --- (CER: 0.129)\n",
      "1) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.112)\n",
      "2) 'he did not say the last as a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.103)\n",
      "3) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxies on his account' --- (CER: 0.103)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  he started to conscious confusion only neither knowing where he was nor what he did\n",
      "Argmax: he started to consces confusion only neither knowing where he was nor what he did --- (CER: 0.036)\n",
      "1) 'he started to consces confusion only neither knowing where he was nor what he did' --- (CER: 0.036)\n",
      "2) 'he started to consces confusion only neither knowwing where he was nor what he did' --- (CER: 0.048)\n",
      "3) 'he started to consces confusion only neither knowing where he was nor what he did ' --- (CER: 0.048)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  i'm here because the matter is of utmost importance and brandd is the one i must see now stand aside\n",
      "Argmax: imcere because he matderacis of ut most omportanceand brand is o vammasea nhostend aside --- (CER: 0.280)\n",
      "1) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nho stend aside' --- (CER: 0.260)\n",
      "2) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhostend aside' --- (CER: 0.270)\n",
      "3) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhestend aside' --- (CER: 0.270)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  of course it ain't said missus bozzle\n",
      "Argmax: of coursit int said missus bozol --- (CER: 0.162)\n",
      "1) 'of cours it int said missus bozol' --- (CER: 0.135)\n",
      "2) 'of cours it int said missus bozol ' --- (CER: 0.135)\n",
      "3) 'of cours it int said missus bozal' --- (CER: 0.135)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  mister verloc was fully responsive now\n",
      "Argmax: mister volockwass fuly respons of mow --- (CER: 0.237)\n",
      "1) 'mister volockwass fuly respons of mow' --- (CER: 0.237)\n",
      "2) 'mister volockwass fuli respons of mow' --- (CER: 0.263)\n",
      "3) 'mister volockwass fuly resplons of mow' --- (CER: 0.263)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  oh what shall we do for a home\n",
      "Argmax: oh what shal we do for a whom --- (CER: 0.100)\n",
      "1) 'oh what shal we do for a whom' --- (CER: 0.100)\n",
      "2) 'ohh what shal we do for a whom' --- (CER: 0.133)\n",
      "3) 'oh what shal we do for a whom ' --- (CER: 0.100)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  line of battle was formed on the north bank of stone's river on the yankee side\n",
      "Argmax: line of battle was formed on the north bank of stones river on the yanky sidt  --- (CER: 0.063)\n",
      "1) 'wine of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.063)\n",
      "2) 'line of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.051)\n",
      "3) 'wine of battle was formed on the north bank of stones river on the yanky side' --- (CER: 0.051)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  from fifteen to twenty minutes will be required to bake them nicely\n",
      "Argmax: fror fifteen t teny minites will be required to bake the nicely --- (CER: 0.090)\n",
      "1) 'fror fifteengt tweny minites will be required to bake the nicely' --- (CER: 0.090)\n",
      "2) 'fror fifteen t tweny minites will be required to bake the nicely' --- (CER: 0.075)\n",
      "3) 'fror fifteengt tweny minutes will be required to bake the nicely' --- (CER: 0.075)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "True:  whom is he going to flog now\n",
      "Argmax: whoom is agoing to flag no --- (CER: 0.214)\n",
      "1) 'whoom is agoing to flagd now' --- (CER: 0.214)\n",
      "2) 'whoom is agoing to flogd now' --- (CER: 0.179)\n",
      "3) 'whoom is agoing to flaugd now' --- (CER: 0.250)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(true_texts)):\n",
    "    beam_search_hypos = bs_results[i][:3]\n",
    "    true_text = true_texts[i]\n",
    "    argmax_text = ctc_decode(log_probs[i].numpy().argmax(-1), ind2char)\n",
    "    print(\"True: \", true_text)\n",
    "    print(f\"Argmax: {argmax_text} --- (CER: {calc_cer(true_text, argmax_text):.3f})\")\n",
    "    for ind, (hypo, score) in enumerate(beam_search_hypos):\n",
    "        print(f\"{ind+1}) '{hypo}' --- (CER: {calc_cer(true_text, hypo):.3f})\")\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f109679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dla-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
