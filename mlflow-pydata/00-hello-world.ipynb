{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "from random import random, randint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package mlflow:\n",
      "\n",
      "NAME\n",
      "    mlflow\n",
      "\n",
      "DESCRIPTION\n",
      "    The ``mlflow`` module provides a high-level \"fluent\" API for starting and managing MLflow runs.\n",
      "    For example:\n",
      "    \n",
      "    .. code:: python\n",
      "    \n",
      "        import mlflow\n",
      "    \n",
      "        mlflow.start_run()\n",
      "        mlflow.log_param(\"my\", \"param\")\n",
      "        mlflow.log_metric(\"score\", 100)\n",
      "        mlflow.end_run()\n",
      "    \n",
      "    You can also use the context manager syntax like this:\n",
      "    \n",
      "    .. code:: python\n",
      "    \n",
      "        with mlflow.start_run() as run:\n",
      "            mlflow.log_param(\"my\", \"param\")\n",
      "            mlflow.log_metric(\"score\", 100)\n",
      "    \n",
      "    which automatically terminates the run at the end of the ``with`` block.\n",
      "    \n",
      "    The fluent tracking API is not currently threadsafe. Any concurrent callers to the tracking API must\n",
      "    implement mutual exclusion manually.\n",
      "    \n",
      "    For a lower level API, see the :py:mod:`mlflow.tracking` module.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _spark_autologging\n",
      "    azure (package)\n",
      "    azureml (package)\n",
      "    catboost\n",
      "    cli\n",
      "    data\n",
      "    db\n",
      "    deployments (package)\n",
      "    entities (package)\n",
      "    exceptions\n",
      "    experiments\n",
      "    fastai\n",
      "    gluon\n",
      "    h2o\n",
      "    keras\n",
      "    lightgbm\n",
      "    mleap\n",
      "    models (package)\n",
      "    onnx\n",
      "    paddle (package)\n",
      "    projects (package)\n",
      "    protos (package)\n",
      "    pyfunc (package)\n",
      "    pyspark (package)\n",
      "    pytorch (package)\n",
      "    rfunc (package)\n",
      "    runs\n",
      "    sagemaker (package)\n",
      "    server (package)\n",
      "    shap\n",
      "    sklearn (package)\n",
      "    spacy\n",
      "    spark\n",
      "    statsmodels\n",
      "    store (package)\n",
      "    tensorflow\n",
      "    tracking (package)\n",
      "    types (package)\n",
      "    utils (package)\n",
      "    version\n",
      "    xgboost\n",
      "\n",
      "CLASSES\n",
      "    mlflow.entities.run.Run(mlflow.entities._mlflow_object._MLflowObject)\n",
      "        mlflow.tracking.fluent.ActiveRun\n",
      "    \n",
      "    class ActiveRun(mlflow.entities.run.Run)\n",
      "     |  ActiveRun(run)\n",
      "     |  \n",
      "     |  Wrapper around :py:class:`mlflow.entities.Run` to enable using Python ``with`` syntax.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ActiveRun\n",
      "     |      mlflow.entities.run.Run\n",
      "     |      mlflow.entities._mlflow_object._MLflowObject\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, exc_type, exc_val, exc_tb)\n",
      "     |  \n",
      "     |  __init__(self, run)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mlflow.entities.run.Run:\n",
      "     |  \n",
      "     |  to_dictionary(self)\n",
      "     |  \n",
      "     |  to_proto(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mlflow.entities.run.Run:\n",
      "     |  \n",
      "     |  from_proto(proto) from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from mlflow.entities.run.Run:\n",
      "     |  \n",
      "     |  data\n",
      "     |      The run data, including metrics, parameters, and tags.\n",
      "     |      \n",
      "     |      :rtype: :py:class:`mlflow.entities.RunData`\n",
      "     |  \n",
      "     |  info\n",
      "     |      The run metadata, such as the run id, start time, and status.\n",
      "     |      \n",
      "     |      :rtype: :py:class:`mlflow.entities.RunInfo`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
      "     |  \n",
      "     |  from_dictionary(the_dict) from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mlflow.entities._mlflow_object._MLflowObject:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    active_run() -> Optional[mlflow.tracking.fluent.ActiveRun]\n",
      "        Get the currently active ``Run``, or None if no such run exists.\n",
      "        \n",
      "        **Note**: You cannot access currently-active run attributes\n",
      "        (parameters, metrics, etc.) through the run returned by ``mlflow.active_run``. In order\n",
      "        to access such attributes, use the :py:class:`mlflow.tracking.MlflowClient` as follows:\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.start_run()\n",
      "            run = mlflow.active_run()\n",
      "            print(\"Active run_id: {}\".format(run.info.run_id))\n",
      "            mlflow.end_run()\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Active run_id: 6f252757005748708cd3aad75d1ff462\n",
      "    \n",
      "    autolog(log_input_examples: bool = False, log_model_signatures: bool = True, log_models: bool = True, disable: bool = False, exclusive: bool = False, disable_for_unsupported_versions: bool = False, silent: bool = False) -> None\n",
      "        Enables (or disables) and configures autologging for all supported integrations.\n",
      "        \n",
      "        The parameters are passed to any autologging integrations that support them.\n",
      "        \n",
      "        See the :ref:`tracking docs <automatic-logging>` for a list of supported autologging\n",
      "        integrations.\n",
      "        \n",
      "        Note that framework-specific configurations set at any point will take precedence over\n",
      "        any configurations set by this function. For example:\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            mlflow.autolog(log_models=False, exclusive=True)\n",
      "            import sklearn\n",
      "        \n",
      "        would enable autologging for `sklearn` with `log_models=False` and `exclusive=True`,\n",
      "        but\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            mlflow.autolog(log_models=False, exclusive=True)\n",
      "            import sklearn\n",
      "            mlflow.sklearn.autolog(log_models=True)\n",
      "        \n",
      "        would enable autologging for `sklearn` with `log_models=True` and `exclusive=False`,\n",
      "        the latter resulting from the default value for `exclusive` in `mlflow.sklearn.autolog`;\n",
      "        other framework autolog functions (e.g. `mlflow.tensorflow.autolog`) would use the\n",
      "        configurations set by `mlflow.autolog` (in this instance, `log_models=False`, `exclusive=True`),\n",
      "        until they are explicitly called by the user.\n",
      "        \n",
      "        :param log_input_examples: If ``True``, input examples from training datasets are collected and\n",
      "                                   logged along with model artifacts during training. If ``False``,\n",
      "                                   input examples are not logged.\n",
      "                                   Note: Input examples are MLflow model attributes\n",
      "                                   and are only collected if ``log_models`` is also ``True``.\n",
      "        :param log_model_signatures: If ``True``,\n",
      "                                     :py:class:`ModelSignatures <mlflow.models.ModelSignature>`\n",
      "                                     describing model inputs and outputs are collected and logged along\n",
      "                                     with model artifacts during training. If ``False``, signatures are\n",
      "                                     not logged. Note: Model signatures are MLflow model attributes\n",
      "                                     and are only collected if ``log_models`` is also ``True``.\n",
      "        :param log_models: If ``True``, trained models are logged as MLflow model artifacts.\n",
      "                           If ``False``, trained models are not logged.\n",
      "                           Input examples and model signatures, which are attributes of MLflow models,\n",
      "                           are also omitted when ``log_models`` is ``False``.\n",
      "        :param disable: If ``True``, disables all supported autologging integrations. If ``False``,\n",
      "                        enables all supported autologging integrations.\n",
      "        :param exclusive: If ``True``, autologged content is not logged to user-created fluent runs.\n",
      "                          If ``False``, autologged content is logged to the active fluent run,\n",
      "                          which may be user-created.\n",
      "        :param disable_for_unsupported_versions: If ``True``, disable autologging for versions of\n",
      "                          all integration libraries that have not been tested against this version\n",
      "                          of the MLflow client or are incompatible.\n",
      "        :param silent: If ``True``, suppress all event logs and warnings from MLflow during autologging\n",
      "                       setup and training execution. If ``False``, show all events and warnings during\n",
      "                       autologging setup and training execution.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import numpy as np\n",
      "            import mlflow.sklearn\n",
      "            from mlflow.tracking import MlflowClient\n",
      "            from sklearn.linear_model import LinearRegression\n",
      "        \n",
      "            def print_auto_logged_info(r):\n",
      "                tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
      "                artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
      "                print(\"run_id: {}\".format(r.info.run_id))\n",
      "                print(\"artifacts: {}\".format(artifacts))\n",
      "                print(\"params: {}\".format(r.data.params))\n",
      "                print(\"metrics: {}\".format(r.data.metrics))\n",
      "                print(\"tags: {}\".format(tags))\n",
      "        \n",
      "            # prepare training data\n",
      "            X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      "            y = np.dot(X, np.array([1, 2])) + 3\n",
      "        \n",
      "            # Auto log all the parameters, metrics, and artifacts\n",
      "            mlflow.autolog()\n",
      "            model = LinearRegression()\n",
      "            with mlflow.start_run() as run:\n",
      "                model.fit(X, y)\n",
      "        \n",
      "            # fetch the auto logged parameters and metrics for ended run\n",
      "            print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: fd10a17d028c47399a55ab8741721ef7\n",
      "            artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/model.pkl']\n",
      "            params: {'copy_X': 'True',\n",
      "                     'normalize': 'False',\n",
      "                     'fit_intercept': 'True',\n",
      "                     'n_jobs': 'None'}\n",
      "            metrics: {'training_score': 1.0,\n",
      "                      'training_rmse': 4.440892098500626e-16,\n",
      "                      'training_r2_score': 1.0,\n",
      "                      'training_mae': 2.220446049250313e-16,\n",
      "                      'training_mse': 1.9721522630525295e-31}\n",
      "            tags: {'estimator_class': 'sklearn.linear_model._base.LinearRegression',\n",
      "                   'estimator_name': 'LinearRegression'}\n",
      "    \n",
      "    create_experiment(name: str, artifact_location: Optional[str] = None) -> str\n",
      "        Create an experiment.\n",
      "        \n",
      "        :param name: The experiment name, which must be unique and is case sensitive\n",
      "        :param artifact_location: The location to store run artifacts.\n",
      "                                  If not provided, the server picks an appropriate default.\n",
      "        :return: String ID of the created experiment.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Create an experiment name, which must be unique and case sensitive\n",
      "            experiment_id = mlflow.create_experiment(\"Social NLP Experiments\")\n",
      "            experiment = mlflow.get_experiment(experiment_id)\n",
      "            print(\"Name: {}\".format(experiment.name))\n",
      "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: Social NLP Experiments\n",
      "            Experiment_id: 1\n",
      "            Artifact Location: file:///.../mlruns/1\n",
      "            Tags= {}\n",
      "            Lifecycle_stage: active\n",
      "    \n",
      "    delete_experiment(experiment_id: str) -> None\n",
      "        Delete an experiment from the backend store.\n",
      "        \n",
      "        :param experiment_id: The The string-ified experiment ID returned from ``create_experiment``.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            experiment_id = mlflow.create_experiment(\"New Experiment\")\n",
      "            mlflow.delete_experiment(experiment_id)\n",
      "        \n",
      "            # Examine the deleted experiment details.\n",
      "            experiment = mlflow.get_experiment(experiment_id)\n",
      "            print(\"Name: {}\".format(experiment.name))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: New Experiment\n",
      "            Artifact Location: file:///.../mlruns/2\n",
      "            Lifecycle_stage: deleted\n",
      "    \n",
      "    delete_run(run_id: str) -> None\n",
      "        Deletes a run with the given ID.\n",
      "        \n",
      "        :param run_id: Unique identifier for the run to delete.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run() as run:\n",
      "                mlflow.log_param(\"p\", 0)\n",
      "        \n",
      "            run_id = run.info.run_id\n",
      "            mlflow.delete_run(run_id)\n",
      "        \n",
      "            print(\"run_id: {}; lifecycle_stage: {}\".format(run_id,\n",
      "                mlflow.get_run(run_id).info.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: 45f4af3e6fd349e58579b27fcb0b8277; lifecycle_stage: deleted\n",
      "    \n",
      "    delete_tag(key: str) -> None\n",
      "        Delete a tag from a run. This is irreversible. If no run is active, this method\n",
      "        will create a new active run.\n",
      "        \n",
      "        :param key: Name of the tag\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            tags = {\"engineering\": \"ML Platform\",\n",
      "                    \"engineering_remote\": \"ML Platform\"}\n",
      "        \n",
      "            with mlflow.start_run() as run:\n",
      "                mlflow.set_tags(tags)\n",
      "        \n",
      "            with mlflow.start_run(run_id=run.info.run_id):\n",
      "                mlflow.delete_tag(\"engineering_remote\")\n",
      "    \n",
      "    end_run(status: str = 'FINISHED') -> None\n",
      "        End an active MLflow run (if there is one).\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Start run and get status\n",
      "            mlflow.start_run()\n",
      "            run = mlflow.active_run()\n",
      "            print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
      "        \n",
      "            # End run and get status\n",
      "            mlflow.end_run()\n",
      "            run = mlflow.get_run(run.info.run_id)\n",
      "            print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
      "            print(\"--\")\n",
      "        \n",
      "            # Check for any active runs\n",
      "            print(\"Active run: {}\".format(mlflow.active_run()))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: b47ee4563368419880b44ad8535f6371; status: RUNNING\n",
      "            run_id: b47ee4563368419880b44ad8535f6371; status: FINISHED\n",
      "            --\n",
      "            Active run: None\n",
      "    \n",
      "    get_artifact_uri(artifact_path: Optional[str] = None) -> str\n",
      "        Get the absolute URI of the specified artifact in the currently active run.\n",
      "        If `path` is not specified, the artifact root URI of the currently active\n",
      "        run will be returned; calls to ``log_artifact`` and ``log_artifacts`` write\n",
      "        artifact(s) to subdirectories of the artifact root URI.\n",
      "        \n",
      "        If no run is active, this method will create a new active run.\n",
      "        \n",
      "        :param artifact_path: The run-relative artifact path for which to obtain an absolute URI.\n",
      "                              For example, \"path/to/artifact\". If unspecified, the artifact root URI\n",
      "                              for the currently active run will be returned.\n",
      "        :return: An *absolute* URI referring to the specified artifact or the currently adtive run's\n",
      "                 artifact root. For example, if an artifact path is provided and the currently active\n",
      "                 run uses an S3-backed store, this may be a uri of the form\n",
      "                 ``s3://<bucket_name>/path/to/artifact/root/path/to/artifact``. If an artifact path\n",
      "                 is not provided and the currently active run uses an S3-backed store, this may be a\n",
      "                 URI of the form ``s3://<bucket_name>/path/to/artifact/root``.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "            with open(\"features.txt\", 'w') as f:\n",
      "                f.write(features)\n",
      "        \n",
      "            # Log the artifact in a directory \"features\" under the root artifact_uri/features\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_artifact(\"features.txt\", artifact_path=\"features\")\n",
      "        \n",
      "                # Fetch the artifact uri root directory\n",
      "                artifact_uri = mlflow.get_artifact_uri()\n",
      "                print(\"Artifact uri: {}\".format(artifact_uri))\n",
      "        \n",
      "                # Fetch a specific artifact uri\n",
      "                artifact_uri = mlflow.get_artifact_uri(artifact_path=\"features/features.txt\")\n",
      "                print(\"Artifact uri: {}\".format(artifact_uri))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Artifact uri: file:///.../0/a46a80f1c9644bd8f4e5dd5553fffce/artifacts\n",
      "            Artifact uri: file:///.../0/a46a80f1c9644bd8f4e5dd5553fffce/artifacts/features/features.txt\n",
      "    \n",
      "    get_experiment(experiment_id: str) -> mlflow.entities.experiment.Experiment\n",
      "        Retrieve an experiment by experiment_id from the backend store\n",
      "        \n",
      "        :param experiment_id: The string-ified experiment ID returned from ``create_experiment``.\n",
      "        :return: :py:class:`mlflow.entities.Experiment`\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            experiment = mlflow.get_experiment(\"0\")\n",
      "            print(\"Name: {}\".format(experiment.name))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: Default\n",
      "            Artifact Location: file:///.../mlruns/0\n",
      "            Tags: {}\n",
      "            Lifecycle_stage: active\n",
      "    \n",
      "    get_experiment_by_name(name: str) -> Optional[mlflow.entities.experiment.Experiment]\n",
      "        Retrieve an experiment by experiment name from the backend store\n",
      "        \n",
      "        :param name: The case senstive experiment name.\n",
      "        :return: An instance of :py:class:`mlflow.entities.Experiment`\n",
      "                 if an experiment with the specified name exists, otherwise None.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Case sensitive name\n",
      "            experiment = mlflow.get_experiment_by_name(\"Default\")\n",
      "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Experiment_id: 0\n",
      "            Artifact Location: file:///.../mlruns/0\n",
      "            Tags: {}\n",
      "            Lifecycle_stage: active\n",
      "    \n",
      "    get_registry_uri() -> str\n",
      "        Get the current registry URI. If none has been specified, defaults to the tracking URI.\n",
      "        \n",
      "        :return: The registry URI.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            # Get the current model registry uri\n",
      "            mr_uri = mlflow.get_registry_uri()\n",
      "            print(\"Current model registry uri: {}\".format(mr_uri))\n",
      "        \n",
      "            # Get the current tracking uri\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "            # They should be the same\n",
      "            assert mr_uri == tracking_uri\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current model registry uri: file:///.../mlruns\n",
      "            Current tracking uri: file:///.../mlruns\n",
      "    \n",
      "    get_run(run_id: str) -> mlflow.entities.run.Run\n",
      "        Fetch the run from backend store. The resulting :py:class:`Run <mlflow.entities.Run>`\n",
      "        contains a collection of run metadata -- :py:class:`RunInfo <mlflow.entities.RunInfo>`,\n",
      "        as well as a collection of run parameters, tags, and metrics --\n",
      "        :py:class:`RunData <mlflow.entities.RunData>`. In the case where multiple metrics with the\n",
      "        same key are logged for the run, the :py:class:`RunData <mlflow.entities.RunData>` contains\n",
      "        the most recently logged value at the largest step for each metric.\n",
      "        \n",
      "        :param run_id: Unique identifier for the run.\n",
      "        \n",
      "        :return: A single :py:class:`mlflow.entities.Run` object, if the run exists. Otherwise,\n",
      "                    raises an exception.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run() as run:\n",
      "                mlflow.log_param(\"p\", 0)\n",
      "        \n",
      "            run_id = run.info.run_id\n",
      "            print(\"run_id: {}; lifecycle_stage: {}\".format(run_id,\n",
      "                mlflow.get_run(run_id).info.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            run_id: 7472befefc754e388e8e922824a0cca5; lifecycle_stage: active\n",
      "    \n",
      "    get_tracking_uri() -> str\n",
      "        Get the current tracking URI. This may not correspond to the tracking URI of\n",
      "        the currently active run, since the tracking URI can be updated via ``set_tracking_uri``.\n",
      "        \n",
      "        :return: The tracking URI.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Get the current tracking uri\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current tracking uri: file:///.../mlruns\n",
      "    \n",
      "    list_experiments(view_type: int = 1, max_results: Optional[int] = None) -> List[mlflow.entities.experiment.Experiment]\n",
      "        :param view_type: Qualify requested type of experiments.\n",
      "        :param max_results: If passed, specifies the maximum number of experiments desired. If not\n",
      "                            passed, all experiments will be returned.\n",
      "        :return: A list of :py:class:`Experiment <mlflow.entities.Experiment>` objects.\n",
      "    \n",
      "    list_run_infos(experiment_id: str, run_view_type: int = 1, max_results: int = 1000, order_by: Optional[List[str]] = None) -> List[mlflow.entities.run_info.RunInfo]\n",
      "        Return run information for runs which belong to the experiment_id.\n",
      "        \n",
      "        :param experiment_id: The experiment id which to search\n",
      "        :param run_view_type: ACTIVE_ONLY, DELETED_ONLY, or ALL runs\n",
      "        :param max_results: Maximum number of results desired.\n",
      "        :param order_by: List of order_by clauses. Currently supported values are\n",
      "               are ``metric.key``, ``parameter.key``, ``tag.key``, ``attribute.key``.\n",
      "               For example, ``order_by=[\"tag.release ASC\", \"metric.click_rate DESC\"]``.\n",
      "        \n",
      "        :return: A list of :py:class:`RunInfo <mlflow.entities.RunInfo>` objects that satisfy the\n",
      "            search expressions.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "            from mlflow.entities import ViewType\n",
      "        \n",
      "            # Create two runs\n",
      "            with mlflow.start_run() as run1:\n",
      "                mlflow.log_param(\"p\", 0)\n",
      "        \n",
      "            with mlflow.start_run() as run2:\n",
      "                mlflow.log_param(\"p\", 1)\n",
      "        \n",
      "            # Delete the last run\n",
      "            mlflow.delete_run(run2.info.run_id)\n",
      "        \n",
      "            def print_run_infos(run_infos):\n",
      "                for r in run_infos:\n",
      "                    print(\"- run_id: {}, lifecycle_stage: {}\".format(r.run_id, r.lifecycle_stage))\n",
      "        \n",
      "            print(\"Active runs:\")\n",
      "            print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.ACTIVE_ONLY))\n",
      "        \n",
      "            print(\"Deleted runs:\")\n",
      "            print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.DELETED_ONLY))\n",
      "        \n",
      "            print(\"All runs:\")\n",
      "            print_run_infos(mlflow.list_run_infos(\"0\", run_view_type=ViewType.ALL))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Active runs:\n",
      "            - run_id: 4937823b730640d5bed9e3e5057a2b34, lifecycle_stage: active\n",
      "            Deleted runs:\n",
      "            - run_id: b13f1badbed842cf9975c023d23da300, lifecycle_stage: deleted\n",
      "            All runs:\n",
      "            - run_id: b13f1badbed842cf9975c023d23da300, lifecycle_stage: deleted\n",
      "            - run_id: 4937823b730640d5bed9e3e5057a2b34, lifecycle_stage: active\n",
      "    \n",
      "    log_artifact(local_path: str, artifact_path: Optional[str] = None) -> None\n",
      "        Log a local file or directory as an artifact of the currently active run. If no run is\n",
      "        active, this method will create a new active run.\n",
      "        \n",
      "        :param local_path: Path to the file to write.\n",
      "        :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Create a features.txt artifact file\n",
      "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "            with open(\"features.txt\", 'w') as f:\n",
      "                f.write(features)\n",
      "        \n",
      "            # With artifact_path=None write features.txt under\n",
      "            # root artifact_uri/artifacts directory\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_artifact(\"features.txt\")\n",
      "    \n",
      "    log_artifacts(local_dir: str, artifact_path: Optional[str] = None) -> None\n",
      "        Log all the contents of a local directory as artifacts of the run. If no run is active,\n",
      "        this method will create a new active run.\n",
      "        \n",
      "        :param local_dir: Path to the directory of files to write.\n",
      "        :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import os\n",
      "            import mlflow\n",
      "        \n",
      "            # Create some files to preserve as artifacts\n",
      "            features = \"rooms, zipcode, median_price, school_rating, transport\"\n",
      "            data = {\"state\": \"TX\", \"Available\": 25, \"Type\": \"Detached\"}\n",
      "        \n",
      "            # Create couple of artifact files under the directory \"data\"\n",
      "            os.makedirs(\"data\", exist_ok=True)\n",
      "            with open(\"data/data.json\", 'w', encoding='utf-8') as f:\n",
      "                json.dump(data, f, indent=2)\n",
      "            with open(\"data/features.txt\", 'w') as f:\n",
      "                f.write(features)\n",
      "        \n",
      "            # Write all files in \"data\" to root artifact_uri/states\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_artifacts(\"data\", artifact_path=\"states\")\n",
      "    \n",
      "    log_dict(dictionary: Any, artifact_file: str) -> None\n",
      "        Log a JSON/YAML-serializable object (e.g. `dict`) as an artifact. The serialization\n",
      "        format (JSON or YAML) is automatically inferred from the extension of `artifact_file`.\n",
      "        If the file extension doesn't exist or match any of [\".json\", \".yml\", \".yaml\"],\n",
      "        JSON format is used.\n",
      "        \n",
      "        :param dictionary: Dictionary to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the dictionary is saved (e.g. \"dir/data.json\").\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            dictionary = {\"k\": \"v\"}\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                # Log a dictionary as a JSON file under the run's root artifact directory\n",
      "                mlflow.log_dict(dictionary, \"data.json\")\n",
      "        \n",
      "                # Log a dictionary as a YAML file in a subdirectory of the run's root artifact directory\n",
      "                mlflow.log_dict(dictionary, \"dir/data.yml\")\n",
      "        \n",
      "                # If the file extension doesn't exist or match any of [\".json\", \".yaml\", \".yml\"],\n",
      "                # JSON format is used.\n",
      "                mlflow.log_dict(dictionary, \"data\")\n",
      "                mlflow.log_dict(dictionary, \"data.txt\")\n",
      "    \n",
      "    log_figure(figure: Union[ForwardRef('matplotlib.figure.Figure'), ForwardRef('plotly.graph_objects.Figure')], artifact_file: str) -> None\n",
      "        Log a figure as an artifact. The following figure objects are supported:\n",
      "        \n",
      "        - `matplotlib.figure.Figure`_\n",
      "        - `plotly.graph_objects.Figure`_\n",
      "        \n",
      "        .. _matplotlib.figure.Figure:\n",
      "            https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html\n",
      "        \n",
      "        .. _plotly.graph_objects.Figure:\n",
      "            https://plotly.com/python-api-reference/generated/plotly.graph_objects.Figure.html\n",
      "        \n",
      "        :param figure: Figure to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the figure is saved (e.g. \"dir/file.png\").\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Matplotlib Example\n",
      "        \n",
      "            import mlflow\n",
      "            import matplotlib.pyplot as plt\n",
      "        \n",
      "            fig, ax = plt.subplots()\n",
      "            ax.plot([0, 1], [2, 3])\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_figure(fig, \"figure.png\")\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Plotly Example\n",
      "        \n",
      "            import mlflow\n",
      "            from plotly import graph_objects as go\n",
      "        \n",
      "            fig = go.Figure(go.Scatter(x=[0, 1], y=[2, 3]))\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_figure(fig, \"figure.html\")\n",
      "    \n",
      "    log_image(image: Union[ForwardRef('numpy.ndarray'), ForwardRef('PIL.Image.Image')], artifact_file: str) -> None\n",
      "        Log an image as an artifact. The following image objects are supported:\n",
      "        \n",
      "        - `numpy.ndarray`_\n",
      "        - `PIL.Image.Image`_\n",
      "        \n",
      "        .. _numpy.ndarray:\n",
      "            https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html\n",
      "        \n",
      "        .. _PIL.Image.Image:\n",
      "            https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image\n",
      "        \n",
      "        Numpy array support\n",
      "            - data type (( ) represents a valid value range):\n",
      "        \n",
      "                - bool\n",
      "                - integer (0 ~ 255)\n",
      "                - unsigned integer (0 ~ 255)\n",
      "                - float (0.0 ~ 1.0)\n",
      "        \n",
      "                .. warning::\n",
      "        \n",
      "                    - Out-of-range integer values will be **clipped** to [0, 255].\n",
      "                    - Out-of-range float values will be **clipped** to [0, 1].\n",
      "        \n",
      "            - shape (H: height, W: width):\n",
      "        \n",
      "                - H x W (Grayscale)\n",
      "                - H x W x 1 (Grayscale)\n",
      "                - H x W x 3 (an RGB channel order is assumed)\n",
      "                - H x W x 4 (an RGBA channel order is assumed)\n",
      "        \n",
      "        :param image: Image to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the image is saved (e.g. \"dir/image.png\").\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Numpy Example\n",
      "        \n",
      "            import mlflow\n",
      "            import numpy as np\n",
      "        \n",
      "            image = np.random.randint(0, 256, size=(100, 100, 3), dtype=np.uint8)\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_image(image, \"image.png\")\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Pillow Example\n",
      "        \n",
      "            import mlflow\n",
      "            from PIL import Image\n",
      "        \n",
      "            image = Image.new(\"RGB\", (100, 100))\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_image(image, \"image.png\")\n",
      "    \n",
      "    log_metric(key: str, value: float, step: Optional[int] = None) -> None\n",
      "        Log a metric under the current run. If no run is active, this method will create\n",
      "        a new active run.\n",
      "        \n",
      "        :param key: Metric name (string).\n",
      "        :param value: Metric value (float). Note that some special values such as +/- Infinity may be\n",
      "                      replaced by other values depending on the store. For example, the\n",
      "                      SQLAlchemy store replaces +/- Infinity with max / min float values.\n",
      "        :param step: Metric step (int). Defaults to zero if unspecified.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_metric(\"mse\", 2500.00)\n",
      "    \n",
      "    log_metrics(metrics: Dict[str, float], step: Optional[int] = None) -> None\n",
      "        Log multiple metrics for the current run. If no run is active, this method will create a new\n",
      "        active run.\n",
      "        \n",
      "        :param metrics: Dictionary of metric_name: String -> value: Float. Note that some special\n",
      "                        values such as +/- Infinity may be replaced by other values depending on\n",
      "                        the store. For example, sql based store may replace +/- Infinity with\n",
      "                        max / min float values.\n",
      "        :param step: A single integer step at which to log the specified\n",
      "                     Metrics. If unspecified, each metric is logged at step zero.\n",
      "        \n",
      "        :returns: None\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            metrics = {\"mse\": 2500.00, \"rmse\": 50.00}\n",
      "        \n",
      "            # Log a batch of metrics\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_metrics(metrics)\n",
      "    \n",
      "    log_param(key: str, value: Any) -> None\n",
      "        Log a parameter under the current run. If no run is active, this method will create\n",
      "        a new active run.\n",
      "        \n",
      "        :param key: Parameter name (string)\n",
      "        :param value: Parameter value (string, but will be string-ified if not)\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_param(\"learning_rate\", 0.01)\n",
      "    \n",
      "    log_params(params: Dict[str, Any]) -> None\n",
      "        Log a batch of params for the current run. If no run is active, this method will create a\n",
      "        new active run.\n",
      "        \n",
      "        :param params: Dictionary of param_name: String -> value: (String, but will be string-ified if\n",
      "                       not)\n",
      "        :returns: None\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            params = {\"learning_rate\": 0.01, \"n_estimators\": 10}\n",
      "        \n",
      "            # Log a batch of parameters\n",
      "            with mlflow.start_run():\n",
      "                mlflow.log_params(params)\n",
      "    \n",
      "    log_text(text: str, artifact_file: str) -> None\n",
      "        Log text as an artifact.\n",
      "        \n",
      "        :param text: String containing text to log.\n",
      "        :param artifact_file: The run-relative artifact file path in posixpath format to which\n",
      "                              the text is saved (e.g. \"dir/file.txt\").\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "                # Log text to a file under the run's root artifact directory\n",
      "                mlflow.log_text(\"text1\", \"file1.txt\")\n",
      "        \n",
      "                # Log text in a subdirectory of the run's root artifact directory\n",
      "                mlflow.log_text(\"text2\", \"dir/file2.txt\")\n",
      "        \n",
      "                # Log HTML text\n",
      "                mlflow.log_text(\"<h1>header</h1>\", \"index.html\")\n",
      "    \n",
      "    register_model(model_uri, name, await_registration_for=300) -> mlflow.entities.model_registry.model_version.ModelVersion\n",
      "        Create a new model version in model registry for the model files specified by ``model_uri``.\n",
      "        Note that this method assumes the model registry backend URI is the same as that of the\n",
      "        tracking backend.\n",
      "        \n",
      "        :param model_uri: URI referring to the MLmodel directory. Use a ``runs:/`` URI if you want to\n",
      "                          record the run ID with the model in model registry. ``models:/`` URIs are\n",
      "                          currently not supported.\n",
      "        :param name: Name of the registered model under which to create a new model version. If a\n",
      "                     registered model with the given name does not exist, it will be created\n",
      "                     automatically.\n",
      "        :param await_registration_for: Number of seconds to wait for the model version to finish\n",
      "                                being created and is in ``READY`` status. By default, the function\n",
      "                                waits for five minutes. Specify 0 or None to skip waiting.\n",
      "        :return: Single :py:class:`mlflow.entities.model_registry.ModelVersion` object created by\n",
      "                 backend.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow.sklearn\n",
      "            from sklearn.ensemble import RandomForestRegressor\n",
      "        \n",
      "            mlflow.set_tracking_uri(\"sqlite:////tmp/mlruns.db\")\n",
      "            params = {\"n_estimators\": 3, \"random_state\": 42}\n",
      "        \n",
      "            # Log MLflow entities\n",
      "            with mlflow.start_run() as run:\n",
      "               rfr = RandomForestRegressor(**params).fit([[0, 1]], [1])\n",
      "               mlflow.log_params(params)\n",
      "               mlflow.sklearn.log_model(rfr, artifact_path=\"sklearn-model\")\n",
      "        \n",
      "            model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
      "            mv = mlflow.register_model(model_uri, \"RandomForestRegressionModel\")\n",
      "            print(\"Name: {}\".format(mv.name))\n",
      "            print(\"Version: {}\".format(mv.version))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Name: RandomForestRegressionModel\n",
      "            Version: 1\n",
      "    \n",
      "    run(uri, entry_point='main', version=None, parameters=None, docker_args=None, experiment_name=None, experiment_id=None, backend='local', backend_config=None, use_conda=True, storage_dir=None, synchronous=True, run_id=None)\n",
      "        Run an MLflow project. The project can be local or stored at a Git URI.\n",
      "        \n",
      "        MLflow provides built-in support for running projects locally or remotely on a Databricks or\n",
      "        Kubernetes cluster. You can also run projects against other targets by installing an appropriate\n",
      "        third-party plugin. See `Community Plugins <../plugins.html#community-plugins>`_ for more\n",
      "        information.\n",
      "        \n",
      "        For information on using this method in chained workflows, see `Building Multistep Workflows\n",
      "        <../projects.html#building-multistep-workflows>`_.\n",
      "        \n",
      "        :raises: :py:class:`mlflow.exceptions.ExecutionException` If a run launched in blocking mode\n",
      "                 is unsuccessful.\n",
      "        \n",
      "        :param uri: URI of project to run. A local filesystem path\n",
      "                    or a Git repository URI (e.g. https://github.com/mlflow/mlflow-example)\n",
      "                    pointing to a project directory containing an MLproject file.\n",
      "        :param entry_point: Entry point to run within the project. If no entry point with the specified\n",
      "                            name is found, runs the project file ``entry_point`` as a script,\n",
      "                            using \"python\" to run ``.py`` files and the default shell (specified by\n",
      "                            environment variable ``$SHELL``) to run ``.sh`` files.\n",
      "        :param version: For Git-based projects, either a commit hash or a branch name.\n",
      "        :param parameters: Parameters (dictionary) for the entry point command.\n",
      "        :param docker_args: Arguments (dictionary) for the docker command.\n",
      "        :param experiment_name: Name of experiment under which to launch the run.\n",
      "        :param experiment_id: ID of experiment under which to launch the run.\n",
      "        :param backend: Execution backend for the run: MLflow provides built-in support for \"local\",\n",
      "                        \"databricks\", and \"kubernetes\" (experimental) backends. If running against\n",
      "                        Databricks, will run against a Databricks workspace determined as follows:\n",
      "                        if a Databricks tracking URI of the form ``databricks://profile`` has been set\n",
      "                        (e.g. by setting the MLFLOW_TRACKING_URI environment variable), will run\n",
      "                        against the workspace specified by <profile>. Otherwise, runs against the\n",
      "                        workspace specified by the default Databricks CLI profile.\n",
      "        :param backend_config: A dictionary, or a path to a JSON file (must end in '.json'), which will\n",
      "                               be passed as config to the backend. The exact content which should be\n",
      "                               provided is different for each execution backend and is documented\n",
      "                               at https://www.mlflow.org/docs/latest/projects.html.\n",
      "        :param use_conda: If True (the default), create a new Conda environment for the run and\n",
      "                          install project dependencies within that environment. Otherwise, run the\n",
      "                          project in the current environment without installing any project\n",
      "                          dependencies.\n",
      "        :param storage_dir: Used only if ``backend`` is \"local\". MLflow downloads artifacts from\n",
      "                            distributed URIs passed to parameters of type ``path`` to subdirectories of\n",
      "                            ``storage_dir``.\n",
      "        :param synchronous: Whether to block while waiting for a run to complete. Defaults to True.\n",
      "                            Note that if ``synchronous`` is False and ``backend`` is \"local\", this\n",
      "                            method will return, but the current process will block when exiting until\n",
      "                            the local run completes. If the current process is interrupted, any\n",
      "                            asynchronous runs launched via this method will be terminated. If\n",
      "                            ``synchronous`` is True and the run fails, the current process will\n",
      "                            error out as well.\n",
      "        :param run_id: Note: this argument is used internally by the MLflow project APIs and should\n",
      "                       not be specified. If specified, the run ID will be used instead of\n",
      "                       creating a new run.\n",
      "        :return: :py:class:`mlflow.projects.SubmittedRun` exposing information (e.g. run ID)\n",
      "                 about the launched run.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            project_uri = \"https://github.com/mlflow/mlflow-example\"\n",
      "            params = {\"alpha\": 0.5, \"l1_ratio\": 0.01}\n",
      "        \n",
      "            # Run MLflow project and create a reproducible conda environment\n",
      "            # on a local host\n",
      "            mlflow.run(project_uri, parameters=params)\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            ...\n",
      "            ...\n",
      "            Elasticnet model (alpha=0.500000, l1_ratio=0.010000):\n",
      "            RMSE: 0.788347345611717\n",
      "            MAE: 0.6155576449938276\n",
      "            R2: 0.19729662005412607\n",
      "            ... mlflow.projects: === Run (ID '6a5109febe5e4a549461e149590d0a7c') succeeded ===\n",
      "    \n",
      "    search_runs(experiment_ids: Optional[List[str]] = None, filter_string: str = '', run_view_type: int = 1, max_results: int = 100000, order_by: Optional[List[str]] = None, output_format: str = 'pandas') -> Union[List[mlflow.entities.run.Run], ForwardRef('pandas.DataFrame')]\n",
      "        Get a pandas DataFrame of runs that fit the search criteria.\n",
      "        \n",
      "        :param experiment_ids: List of experiment IDs. None will default to the active experiment.\n",
      "        :param filter_string: Filter query string, defaults to searching all runs.\n",
      "        :param run_view_type: one of enum values ``ACTIVE_ONLY``, ``DELETED_ONLY``, or ``ALL`` runs\n",
      "                                defined in :py:class:`mlflow.entities.ViewType`.\n",
      "        :param max_results: The maximum number of runs to put in the dataframe. Default is 100,000\n",
      "                            to avoid causing out-of-memory issues on the user's machine.\n",
      "        :param order_by: List of columns to order by (e.g., \"metrics.rmse\"). The ``order_by`` column\n",
      "                         can contain an optional ``DESC`` or ``ASC`` value. The default is ``ASC``.\n",
      "                         The default ordering is to sort by ``start_time DESC``, then ``run_id``.\n",
      "        :param output_format: The output format to be returned. If ``pandas``, a ``pandas.DataFrame``\n",
      "                              is returned and, if ``list``, a list of :py:class:`mlflow.entities.Run`\n",
      "                              is returned.\n",
      "        \n",
      "        :return: If output_format is ``list``: a list of :py:class:`mlflow.entities.Run`. If\n",
      "                 output_format is ``pandas``: ``pandas.DataFrame`` of runs, where each metric,\n",
      "                 parameter, and tag is expanded into its own column named metrics.*, params.*, or\n",
      "                 tags.* respectively. For runs that don't have a particular metric, parameter, or tag,\n",
      "                 the value for the corresponding column is (NumPy) ``Nan``, ``None``, or ``None``\n",
      "                 respectively.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Create an experiment and log two runs under it\n",
      "            experiment_id = mlflow.create_experiment(\"Social NLP Experiments\")\n",
      "            with mlflow.start_run(experiment_id=experiment_id):\n",
      "                mlflow.log_metric(\"m\", 1.55)\n",
      "                mlflow.set_tag(\"s.release\", \"1.1.0-RC\")\n",
      "            with mlflow.start_run(experiment_id=experiment_id):\n",
      "                mlflow.log_metric(\"m\", 2.50)\n",
      "                mlflow.set_tag(\"s.release\", \"1.2.0-GA\")\n",
      "        \n",
      "            # Search all runs in experiment_id\n",
      "            df = mlflow.search_runs([experiment_id], order_by=[\"metrics.m DESC\"])\n",
      "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
      "            print(\"--\")\n",
      "        \n",
      "            # Search the experiment_id using a filter_string with tag\n",
      "            # that has a case insensitive pattern\n",
      "            filter_string = \"tags.s.release ILIKE '%rc%'\"\n",
      "            df = mlflow.search_runs([experiment_id], filter_string=filter_string)\n",
      "            print(df[[\"metrics.m\", \"tags.s.release\", \"run_id\"]])\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "               metrics.m tags.s.release                            run_id\n",
      "            0       2.50       1.2.0-GA  147eed886ab44633902cc8e19b2267e2\n",
      "            1       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
      "            --\n",
      "               metrics.m tags.s.release                            run_id\n",
      "            0       1.55       1.1.0-RC  5cc7feaf532f496f885ad7750809c4d4\n",
      "    \n",
      "    set_experiment(experiment_name: str) -> None\n",
      "        Set given experiment as active experiment. If experiment does not exist, create an experiment\n",
      "        with provided name.\n",
      "        \n",
      "        :param experiment_name: Case sensitive name of an experiment to be activated.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Set an experiment name, which must be unique and case sensitive.\n",
      "            mlflow.set_experiment(\"Social NLP Experiments\")\n",
      "        \n",
      "            # Get Experiment Details\n",
      "            experiment = mlflow.get_experiment_by_name(\"Social NLP Experiments\")\n",
      "            print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
      "            print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
      "            print(\"Tags: {}\".format(experiment.tags))\n",
      "            print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Experiment_id: 1\n",
      "            Artifact Location: file:///.../mlruns/1\n",
      "            Tags: {}\n",
      "            Lifecycle_stage: active\n",
      "    \n",
      "    set_registry_uri(uri: str) -> None\n",
      "        Set the registry server URI. This method is especially useful if you have a registry server\n",
      "        that's different from the tracking server.\n",
      "        \n",
      "        :param uri:\n",
      "        \n",
      "                    - An empty string, or a local file path, prefixed with ``file:/``. Data is stored\n",
      "                      locally at the provided file (or ``./mlruns`` if empty).\n",
      "                    - An HTTP URI like ``https://my-tracking-server:5000``.\n",
      "                    - A Databricks workspace, provided as the string \"databricks\" or, to use a\n",
      "                      Databricks CLI\n",
      "                      `profile <https://github.com/databricks/databricks-cli#installation>`_,\n",
      "                      \"databricks://<profileName>\".\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mflow\n",
      "        \n",
      "            # Set model registry uri, fetch the set uri, and compare\n",
      "            # it with the tracking uri. They should be different\n",
      "            mlflow.set_registry_uri(\"sqlite:////tmp/registry.db\")\n",
      "            mr_uri = mlflow.get_registry_uri()\n",
      "            print(\"Current registry uri: {}\".format(mr_uri))\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "            # They should be different\n",
      "            assert tracking_uri != mr_uri\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current registry uri: sqlite:////tmp/registry.db\n",
      "            Current tracking uri: file:///.../mlruns\n",
      "    \n",
      "    set_tag(key: str, value: Any) -> None\n",
      "        Set a tag under the current run. If no run is active, this method will create a\n",
      "        new active run.\n",
      "        \n",
      "        :param key: Tag name (string)\n",
      "        :param value: Tag value (string, but will be string-ified if not)\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            with mlflow.start_run():\n",
      "               mlflow.set_tag(\"release.version\", \"2.2.0\")\n",
      "    \n",
      "    set_tags(tags: Dict[str, Any]) -> None\n",
      "        Log a batch of tags for the current run. If no run is active, this method will create a\n",
      "        new active run.\n",
      "        \n",
      "        :param tags: Dictionary of tag_name: String -> value: (String, but will be string-ified if\n",
      "                     not)\n",
      "        :returns: None\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            tags = {\"engineering\": \"ML Platform\",\n",
      "                    \"release.candidate\": \"RC1\",\n",
      "                    \"release.version\": \"2.2.0\"}\n",
      "        \n",
      "            # Set a batch of tags\n",
      "            with mlflow.start_run():\n",
      "                mlflow.set_tags(tags)\n",
      "    \n",
      "    set_tracking_uri(uri: str) -> None\n",
      "        Set the tracking server URI. This does not affect the\n",
      "        currently active run (if one exists), but takes effect for successive runs.\n",
      "        \n",
      "        :param uri:\n",
      "        \n",
      "                    - An empty string, or a local file path, prefixed with ``file:/``. Data is stored\n",
      "                      locally at the provided file (or ``./mlruns`` if empty).\n",
      "                    - An HTTP URI like ``https://my-tracking-server:5000``.\n",
      "                    - A Databricks workspace, provided as the string \"databricks\" or, to use a\n",
      "                      Databricks CLI\n",
      "                      `profile <https://github.com/databricks/databricks-cli#installation>`_,\n",
      "                      \"databricks://<profileName>\".\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            mlflow.set_tracking_uri(\"file:///tmp/my_tracking\")\n",
      "            tracking_uri = mlflow.get_tracking_uri()\n",
      "            print(\"Current tracking uri: {}\".format(tracking_uri))\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            Current tracking uri: file:///tmp/my_tracking\n",
      "    \n",
      "    start_run(run_id: str = None, experiment_id: Optional[str] = None, run_name: Optional[str] = None, nested: bool = False, tags: Optional[Dict[str, Any]] = None) -> mlflow.tracking.fluent.ActiveRun\n",
      "        Start a new MLflow run, setting it as the active run under which metrics and parameters\n",
      "        will be logged. The return value can be used as a context manager within a ``with`` block;\n",
      "        otherwise, you must call ``end_run()`` to terminate the current run.\n",
      "        \n",
      "        If you pass a ``run_id`` or the ``MLFLOW_RUN_ID`` environment variable is set,\n",
      "        ``start_run`` attempts to resume a run with the specified run ID and\n",
      "        other parameters are ignored. ``run_id`` takes precedence over ``MLFLOW_RUN_ID``.\n",
      "        \n",
      "        If resuming an existing run, the run status is set to ``RunStatus.RUNNING``.\n",
      "        \n",
      "        MLflow sets a variety of default tags on the run, as defined in\n",
      "        :ref:`MLflow system tags <system_tags>`.\n",
      "        \n",
      "        :param run_id: If specified, get the run with the specified UUID and log parameters\n",
      "                         and metrics under that run. The run's end time is unset and its status\n",
      "                         is set to running, but the run's other attributes (``source_version``,\n",
      "                         ``source_type``, etc.) are not changed.\n",
      "        :param experiment_id: ID of the experiment under which to create the current run (applicable\n",
      "                              only when ``run_id`` is not specified). If ``experiment_id`` argument\n",
      "                              is unspecified, will look for valid experiment in the following order:\n",
      "                              activated using ``set_experiment``, ``MLFLOW_EXPERIMENT_NAME``\n",
      "                              environment variable, ``MLFLOW_EXPERIMENT_ID`` environment variable,\n",
      "                              or the default experiment as defined by the tracking server.\n",
      "        :param run_name: Name of new run (stored as a ``mlflow.runName`` tag).\n",
      "                         Used only when ``run_id`` is unspecified.\n",
      "        :param nested: Controls whether run is nested in parent run. ``True`` creates a nested run.\n",
      "        :param tags: An optional dictionary of string keys and values to set as tags on the run.\n",
      "                     If a run is being resumed, these tags are set on the resumed run. If a new run is\n",
      "                     being created, these tags are set on the new run.\n",
      "        :return: :py:class:`mlflow.ActiveRun` object that acts as a context manager wrapping\n",
      "                 the run's state.\n",
      "        \n",
      "        .. code-block:: python\n",
      "            :caption: Example\n",
      "        \n",
      "            import mlflow\n",
      "        \n",
      "            # Create nested runs\n",
      "            with mlflow.start_run(run_name='PARENT_RUN') as parent_run:\n",
      "                mlflow.log_param(\"parent\", \"yes\")\n",
      "                with mlflow.start_run(run_name='CHILD_RUN', nested=True) as child_run:\n",
      "                    mlflow.log_param(\"child\", \"yes\")\n",
      "        \n",
      "            print(\"parent run_id: {}\".format(parent_run.info.run_id))\n",
      "            print(\"child run_id : {}\".format(child_run.info.run_id))\n",
      "            print(\"--\")\n",
      "        \n",
      "            # Search all child runs with a parent id\n",
      "            query = \"tags.mlflow.parentRunId = '{}'\".format(parent_run.info.run_id)\n",
      "            results = mlflow.search_runs(filter_string=query)\n",
      "            print(results[[\"run_id\", \"params.child\", \"tags.mlflow.runName\"]])\n",
      "        \n",
      "        .. code-block:: text\n",
      "            :caption: Output\n",
      "        \n",
      "            parent run_id: 5ec0e7ae18f54c2694ffb48c2fccf25c\n",
      "            child run_id : 78b3b0d264b44cd29e8dc389749bb4be\n",
      "            --\n",
      "                                         run_id params.child tags.mlflow.runName\n",
      "            0  78b3b0d264b44cd29e8dc389749bb4be          yes           CHILD_RUN\n",
      "\n",
      "DATA\n",
      "    __all__ = ['ActiveRun', 'log_param', 'log_params', 'log_metric', 'log_...\n",
      "\n",
      "VERSION\n",
      "    1.20.0\n",
      "\n",
      "FILE\n",
      "    /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/mlflow/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(experiment_name: str = \"experiment 1\", run_name: str = \"\"):\n",
    "    mlflow.set_experiment(experiment_name=experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as r:\n",
    "        print(\"Running hello world example\")\n",
    "        print(\"Model run:\", r.info.run_uuid)\n",
    "        mlflow.set_tag(\"mlflow.runName\", run_name)\n",
    "        mlflow.log_param(\"param1\", randint(0, 100))\n",
    "        \n",
    "        mlflow.log_metric(\"foo\", random())\n",
    "        mlflow.log_metric(\"foo1\", random() + 1)\n",
    "        \n",
    "        mlflow.set_tag(\"run_origin\", \"jupyter_notebook\")\n",
    "        \n",
    "        if not os.path.exists(\"outputs\"):\n",
    "            os.makedirs(\"outputs\")\n",
    "            \n",
    "        with open(\"outputs/test.txt\", \"w\") as f:\n",
    "            f.write(\"hello world!\")\n",
    "            \n",
    "        mlflow.log_artifact(\"outputs\", artifact_path=\"artifact\")\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'experiment 1' does not exist. Creating a new experiment\n",
      "Running hello world example\n",
      "Model run: 21eb0c1626d5457aaa022ec95c5c8ea7\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hello world example\n",
      "Model run: 60ba1945f55740d7a536c84d68058898\n"
     ]
    }
   ],
   "source": [
    "run(run_name=\"LocalRun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up MLflow Tracking User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mlflow ui --port 8990\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLflow Version:\", mlflow.__version__)\n",
    "mlflow.set_tracking_uri(\"http://localhost:1234\")\n",
    "print(\"Tracking URI:\", mlflow.tracking.get_tracking_uri)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
