{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Data\n",
    "\n",
    "First we load data from S3. It is stored as a trivial CSV file with three columns\n",
    "1. product name\n",
    "2. review text\n",
    "3. rating (1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>review</td>\n",
       "      <td>rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                                               name   \n",
       "1                           Planetwise Flannel Wipes   \n",
       "2                              Planetwise Wipe Pouch   \n",
       "3                Annas Dream Full Quilt with 2 Shams   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0                                             review  rating  \n",
       "1  These flannel wipes are OK, but in my opinion ...       3  \n",
       "2  it came early and was not disappointed. i love...       5  \n",
       "3  Very soft and comfortable and warmer than it l...       5  \n",
       "4  This is a product well worth the purchase.  I ...       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema =  StructType([\n",
    "    StructField('name',StringType(),True),\n",
    "    StructField('review',StringType(), True),\n",
    "    StructField('rating',StringType(), True),\n",
    "])\n",
    "\n",
    "raw_data = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"s3://dimajix-training/data/amazon_baby\")\n",
    "raw_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Clean and Cache Data\n",
    "\n",
    "We need to convert the \"rating\" columns to an integer - but this will obviously fail for the first record, as this one contains the CSV header. So we need to perform some cleanup after trying to convert the data.\n",
    "\n",
    "For helping distributing the workload, we repartition the DataFrame and also cache it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Really happy with this purchase. I was looking...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semanario (7) Little Girls 14k Gold Overlay Ba...</td>\n",
       "      <td>. I am pleased with product. I love the bangle...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neurosmith - Music Blocks with Mozart Music Ca...</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fisher Price Nesting Action Vehicles</td>\n",
       "      <td>This is a great toy.  The wheels really work a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                        Lamaze Peekaboo, I Love You   \n",
       "1                          Our Baby Girl Memory Book   \n",
       "2  Semanario (7) Little Girls 14k Gold Overlay Ba...   \n",
       "3  Neurosmith - Music Blocks with Mozart Music Ca...   \n",
       "4               Fisher Price Nesting Action Vehicles   \n",
       "\n",
       "                                              review  rating  \n",
       "0  One of baby's first and favorite books, and it...       4  \n",
       "1  Really happy with this purchase. I was looking...       5  \n",
       "2  . I am pleased with product. I love the bangle...       4  \n",
       "3  It takes a youthful spirit of inquiry and fasc...       5  \n",
       "4  This is a great toy.  The wheels really work a...       5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data.withColumn('rating',col('rating').cast(IntegerType())) \\\n",
    "    .filter(col('rating').isNotNull()) \\\n",
    "    .filter(col('review').isNotNull()) \\\n",
    "    .repartition(31) \\\n",
    "    .cache()\n",
    "\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split Train Data / Test Data\n",
    "\n",
    "Now let's do the usual split of our data into a training data set and a validation data set. Let's use 80% of all reviews for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 139461\n",
      "test_data: 34861\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data.randomSplit([0.8,0.2], seed=1)\n",
    "\n",
    "print(\"train_data: %d\" % train_data.count())\n",
    "print(\"test_data: %d\" % test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Custom Transformers\n",
    "\n",
    "In order to work with the text data, we need some custom transformers, which are not provided by PySpark. Luckily we can wrap any given Python algorithm into a PySpark ML Transformer, which can be directly used inside a ML Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implement Transformer for Removing Punctuations\n",
    "\n",
    "We need a custom Transformer to build the pipeline. The transformer should remove all punctuations from a given column containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    import string\n",
    "    if text:\n",
    "        for c in string.punctuation:\n",
    "            text = text.replace(c, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "class PunctuationCleanupTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        \"\"\"\n",
    "        Constructor of PunctuationCleanupTransformer which takes two arguments:\n",
    "        inputCol - name of input column\n",
    "        outputCol - name of output column\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \"\"\"\n",
    "        Protecetd _transform method which will be called by the public transform\n",
    "        method. You should not call this method directly.\n",
    "        \"\"\"\n",
    "        remove_punctuation_udf = udf(remove_punctuations, StringType())\n",
    "        return dataset.withColumn(self.outputCol, remove_punctuation_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Transformer\n",
    "\n",
    "Lets create an instance of the Transformer and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>One of baby s first and favorite books  and it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Really happy with this purchase. I was looking...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really happy with this purchase  I was looking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semanario (7) Little Girls 14k Gold Overlay Ba...</td>\n",
       "      <td>. I am pleased with product. I love the bangle...</td>\n",
       "      <td>4</td>\n",
       "      <td>I am pleased with product  I love the bangle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neurosmith - Music Blocks with Mozart Music Ca...</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "      <td>5</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                        Lamaze Peekaboo, I Love You   \n",
       "1                          Our Baby Girl Memory Book   \n",
       "2  Semanario (7) Little Girls 14k Gold Overlay Ba...   \n",
       "3  Neurosmith - Music Blocks with Mozart Music Ca...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  One of baby's first and favorite books, and it...       4   \n",
       "1  Really happy with this purchase. I was looking...       5   \n",
       "2  . I am pleased with product. I love the bangle...       4   \n",
       "3  It takes a youthful spirit of inquiry and fasc...       5   \n",
       "\n",
       "                                        clean_review  \n",
       "0  One of baby s first and favorite books  and it...  \n",
       "1  Really happy with this purchase  I was looking...  \n",
       "2    I am pleased with product  I love the bangle...  \n",
       "3  It takes a youthful spirit of inquiry and fasc...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review')\n",
    "clean_data = cleaner.transform(data)\n",
    "\n",
    "clean_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Implement Transformer for Stemming\n",
    "\n",
    "We need to stem words, and for doing so we use the Python NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stem_word(words):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(word) for word in words]\n",
    "\n",
    "\n",
    "class PorterStemmerTransformer(Transformer):\n",
    "    def __init__(self, inputCol, outputCol):\n",
    "        \"\"\"\n",
    "        Constructor of PorterStemmerTransformer which takes two arguments:\n",
    "        inputCol - name of input column\n",
    "        outputCol - name of output column\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.outputCol = outputCol\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \"\"\"\n",
    "        Protecetd _transform method which will be called by the public transform\n",
    "        method. You should not call this method directly.\n",
    "        \"\"\"\n",
    "        stem_word_udf = udf(stem_word, ArrayType(StringType()))\n",
    "        return dataset.withColumn(self.outputCol, stem_word_udf(self.inputCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Transformer\n",
    "\n",
    "Again we want to test the `PorterStemmerTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>words</th>\n",
       "      <th>stemmed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>[one, of, baby's, first, and, favorite, books,...</td>\n",
       "      <td>[one, of, baby', first, and, favorit, books,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Really happy with this purchase. I was looking...</td>\n",
       "      <td>5</td>\n",
       "      <td>[really, happy, with, this, purchase., i, was,...</td>\n",
       "      <td>[realli, happi, with, thi, purchase., i, wa, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semanario (7) Little Girls 14k Gold Overlay Ba...</td>\n",
       "      <td>. I am pleased with product. I love the bangle...</td>\n",
       "      <td>4</td>\n",
       "      <td>[., i, am, pleased, with, product., i, love, t...</td>\n",
       "      <td>[., i, am, pleas, with, product., i, love, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neurosmith - Music Blocks with Mozart Music Ca...</td>\n",
       "      <td>It takes a youthful spirit of inquiry and fasc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[it, takes, a, youthful, spirit, of, inquiry, ...</td>\n",
       "      <td>[it, take, a, youth, spirit, of, inquiri, and,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                        Lamaze Peekaboo, I Love You   \n",
       "1                          Our Baby Girl Memory Book   \n",
       "2  Semanario (7) Little Girls 14k Gold Overlay Ba...   \n",
       "3  Neurosmith - Music Blocks with Mozart Music Ca...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  One of baby's first and favorite books, and it...       4   \n",
       "1  Really happy with this purchase. I was looking...       5   \n",
       "2  . I am pleased with product. I love the bangle...       4   \n",
       "3  It takes a youthful spirit of inquiry and fasc...       5   \n",
       "\n",
       "                                               words  \\\n",
       "0  [one, of, baby's, first, and, favorite, books,...   \n",
       "1  [really, happy, with, this, purchase., i, was,...   \n",
       "2  [., i, am, pleased, with, product., i, love, t...   \n",
       "3  [it, takes, a, youthful, spirit, of, inquiry, ...   \n",
       "\n",
       "                                      stemmed_review  \n",
       "0  [one, of, baby', first, and, favorit, books,, ...  \n",
       "1  [realli, happi, with, thi, purchase., i, wa, l...  \n",
       "2  [., i, am, pleas, with, product., i, love, the...  \n",
       "3  [it, take, a, youth, spirit, of, inquiri, and,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import *\n",
    "\n",
    "# First we need to Tokenize each line. In order to perform this task, we implement the following steps\n",
    "# 1. Instantiate a Tokenizer instance from pyspark.ml.feature\n",
    "# 2. Transform the raw data using the tokenizer\n",
    "tokenizer = Tokenizer(inputCol='review', outputCol='words')\n",
    "tokenized_data = tokenizer.transform(data)\n",
    "\n",
    "# Then we can instantiate the Stemmer and use it on the words\n",
    "stemmer = PorterStemmerTransformer(inputCol='words', outputCol='stemmed_review')\n",
    "stemmed_data = stemmer.transform(tokenized_data)\n",
    "\n",
    "stemmed_data.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Create Prediciton Model\n",
    "\n",
    "Now we have all parts and helpers in place to create a predicitive model using a PySpark ML Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create ML Pipeline\n",
    "\n",
    "Now we have all components for creating an initial ML Pipeline. Remember that we have been using the following components before\n",
    "\n",
    "* PunctuationCleanupTransformer - remove punctuations from reviews\n",
    "* Tokenizer - for splitting reviews into words\n",
    "* StopWordRemover - for removing stop words\n",
    "* PorterStemmerTransformer - for stemming words\n",
    "* NGram - for creating NGrams (we'll use two words per n-gram)\n",
    "* CountVectorizer - for creating bag-of-word features from the words\n",
    "* IDF - for creating TF-IDF features from the NGram counts\n",
    "* LogisticRegression - for creating the real model\n",
    "\n",
    "You also need to transform the incoming rating (1-5) to a sentiment (0 or 1) and you need to drop reviews with a rating of 3. This can be done using one ore more SQLTransformer instances. Inside the SQLTransformer instance you simply write SQL code and access the current DataFrame via `__THIS__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "\n",
    "stopWords = ['the','a','and','or', 'it', 'this', 'of', 'an', 'as', 'in', 'on', 'is', 'are', 'to', 'was', 'for', 'then', 'i']\n",
    "stopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "\n",
    "stages = [\n",
    "    PunctuationCleanupTransformer(inputCol='review', outputCol='clean_review'),\n",
    "    SQLTransformer(statement='SELECT *,CASE WHEN rating < 3 THEN 0.0 ELSE 1.0 END AS sentiment FROM __THIS__ WHERE rating <> 3'),\n",
    "    Tokenizer(inputCol='clean_review', outputCol='words'),\n",
    "    StopWordsRemover(inputCol='words', outputCol='vwords', stopWords=stopWords),\n",
    "    PorterStemmerTransformer(inputCol='vwords', outputCol='stems'),\n",
    "    NGram(inputCol='stems', outputCol='ngrams', n=3),\n",
    "    CountVectorizer(inputCol='ngrams', outputCol='tf', minDF=2.0),\n",
    "    IDF(inputCol='tf', outputCol='features'),\n",
    "    LogisticRegression(featuresCol='features',labelCol='sentiment')\n",
    "]\n",
    "pipe = Pipeline(stages = stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Fit Pipeline Model\n",
    "Using training data, we create a PipelineModel by fitting the Pipeline to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Predict Data\n",
    "\n",
    "Let us do some predictions of the test data using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>vwords</th>\n",
       "      <th>stems</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>tf</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>My son is now 2 years old, we bought this when...</td>\n",
       "      <td>5</td>\n",
       "      <td>My son is now 2 years old  we bought this when...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[my, son, is, now, 2, years, old, , we, bought...</td>\n",
       "      <td>[son, 2, years, old, , bought, 7, months, , ha...</td>\n",
       "      <td>[son, 2, year, old, , bought, 7, month, , hand...</td>\n",
       "      <td>[son 2 year, 2 year old, year old , old  bough...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-4044.31968499, 4044.31968499]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>We have used this to enclose our wood stove to...</td>\n",
       "      <td>5</td>\n",
       "      <td>We have used this to enclose our wood stove to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, have, used, this, to, enclose, our, wood,...</td>\n",
       "      <td>[used, enclose, wood, stove, protect, kids, , ...</td>\n",
       "      <td>[use, enclos, wood, stove, protect, kid, , wor...</td>\n",
       "      <td>[use enclos wood, enclos wood stove, wood stov...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3164.92569261, 3164.92569261]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*SPECIAL PROMOTION*The Art of CureTM *SAFETY K...</td>\n",
       "      <td>So as much as I love all things natural, we we...</td>\n",
       "      <td>5</td>\n",
       "      <td>So as much as I love all things natural  we we...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[so, as, much, as, i, love, all, things, natur...</td>\n",
       "      <td>[much, love, things, natural, , skeptical, pro...</td>\n",
       "      <td>[much, love, thing, natur, , skeptic, product,...</td>\n",
       "      <td>[much love thing, love thing natur, thing natu...</td>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.82692062624, 0.0, 3.22663271037, 0.0, 0.0, ...</td>\n",
       "      <td>[-5341.67880727, 5341.67880727]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100% Solid Wood Safety Rail Guard &amp;bull; Honey...</td>\n",
       "      <td>This was a beautiful piece and fit nicely with...</td>\n",
       "      <td>5</td>\n",
       "      <td>This was a beautiful piece and fit nicely with...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[this, was, a, beautiful, piece, and, fit, nic...</td>\n",
       "      <td>[beautiful, piece, fit, nicely, bunk, beds, , ...</td>\n",
       "      <td>[beauti, piec, fit, nice, bunk, bed, , , easi,...</td>\n",
       "      <td>[beauti piec fit, piec fit nice, fit nice bunk...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-1222.1505214, 1222.1505214]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 Handle 8oz. Cup with Flip-It Straw Top, 1-pk...</td>\n",
       "      <td>There's nothing wrong with the cup itself, I l...</td>\n",
       "      <td>1</td>\n",
       "      <td>There s nothing wrong with the cup itself  I l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[there, s, nothing, wrong, with, the, cup, its...</td>\n",
       "      <td>[nothing, wrong, cup, , love, cup, , make, mis...</td>\n",
       "      <td>[noth, wrong, cup, , love, cup, , make, mistak...</td>\n",
       "      <td>[noth wrong cup, wrong cup , cup  love,  love ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1610.33450113, -1610.33450113]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 Red Hens Whole Roost Bag W/ Changing Pad-Che...</td>\n",
       "      <td>I was amazed when I saw how cheap this bag was...</td>\n",
       "      <td>5</td>\n",
       "      <td>I was amazed when I saw how cheap this bag was...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, was, amazed, when, i, saw, how, cheap, thi...</td>\n",
       "      <td>[amazed, saw, cheap, bag, compared, others, ev...</td>\n",
       "      <td>[amaz, saw, cheap, bag, compar, other, even, o...</td>\n",
       "      <td>[amaz saw cheap, saw cheap bag, cheap bag comp...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-992.717734987, 992.717734987]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 in 1 Floating Baby Bottle Brush</td>\n",
       "      <td>I have no idea why I even thought of getting t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I have no idea why I even thought of getting t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[i, have, no, idea, why, i, even, thought, of,...</td>\n",
       "      <td>[idea, even, thought, getting, , , exterior, p...</td>\n",
       "      <td>[idea, even, thought, get, , , exterior, packa...</td>\n",
       "      <td>[idea even thought, even thought get, thought ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-837.094291579, 837.094291579]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24 Sq. Ft. (set of 24 + borders) 'We Sell Mats...</td>\n",
       "      <td>I gave the mats to my daughter's preschool as ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I gave the mats to my daughter s preschool as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, gave, the, mats, to, my, daughter, s, pres...</td>\n",
       "      <td>[gave, mats, daughter, preschool, gift, , kids...</td>\n",
       "      <td>[gave, mat, daughter, preschool, gift, , kid, ...</td>\n",
       "      <td>[gave mat daughter, mat daughter preschool, da...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-677.727977688, 677.727977688]</td>\n",
       "      <td>[4.63958417669e-295, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Packs of NUK Replacement Silicone Spout, Clear</td>\n",
       "      <td>These are the best tips on the Nuk Bottles tha...</td>\n",
       "      <td>5</td>\n",
       "      <td>These are the best tips on the Nuk Bottles tha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[these, are, the, best, tips, on, the, nuk, bo...</td>\n",
       "      <td>[best, tips, nuk, bottles, get, teeth, start, ...</td>\n",
       "      <td>[best, tip, nuk, bottl, get, teeth, start, che...</td>\n",
       "      <td>[best tip nuk, tip nuk bottl, nuk bottl get, b...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-217.578766464, 217.578766464]</td>\n",
       "      <td>[3.21175452925e-95, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aden + Anais Issie Security Blanket Set Declan...</td>\n",
       "      <td>My 10 month old son is a great sleeper and has...</td>\n",
       "      <td>5</td>\n",
       "      <td>My 10 month old son is a great sleeper and has...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[my, 10, month, old, son, is, a, great, sleepe...</td>\n",
       "      <td>[10, month, old, son, great, sleeper, since, a...</td>\n",
       "      <td>[10, month, old, son, great, sleeper, sinc, ar...</td>\n",
       "      <td>[10 month old, month old son, old son great, s...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 3.08723358449, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-6818.20425706, 6818.20425706]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  *SPECIAL PROMOTION*The Art of CureTM *SAFETY K...   \n",
       "3  100% Solid Wood Safety Rail Guard &bull; Honey...   \n",
       "4  2 Handle 8oz. Cup with Flip-It Straw Top, 1-pk...   \n",
       "5  2 Red Hens Whole Roost Bag W/ Changing Pad-Che...   \n",
       "6                  2 in 1 Floating Baby Bottle Brush   \n",
       "7  24 Sq. Ft. (set of 24 + borders) 'We Sell Mats...   \n",
       "8   3 Packs of NUK Replacement Silicone Spout, Clear   \n",
       "9  Aden + Anais Issie Security Blanket Set Declan...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  My son is now 2 years old, we bought this when...       5   \n",
       "1  We have used this to enclose our wood stove to...       5   \n",
       "2  So as much as I love all things natural, we we...       5   \n",
       "3  This was a beautiful piece and fit nicely with...       5   \n",
       "4  There's nothing wrong with the cup itself, I l...       1   \n",
       "5  I was amazed when I saw how cheap this bag was...       5   \n",
       "6  I have no idea why I even thought of getting t...       1   \n",
       "7  I gave the mats to my daughter's preschool as ...       5   \n",
       "8  These are the best tips on the Nuk Bottles tha...       5   \n",
       "9  My 10 month old son is a great sleeper and has...       5   \n",
       "\n",
       "                                        clean_review sentiment  \\\n",
       "0  My son is now 2 years old  we bought this when...       1.0   \n",
       "1  We have used this to enclose our wood stove to...       1.0   \n",
       "2  So as much as I love all things natural  we we...       1.0   \n",
       "3  This was a beautiful piece and fit nicely with...       1.0   \n",
       "4  There s nothing wrong with the cup itself  I l...       0.0   \n",
       "5  I was amazed when I saw how cheap this bag was...       1.0   \n",
       "6  I have no idea why I even thought of getting t...       0.0   \n",
       "7  I gave the mats to my daughter s preschool as ...       1.0   \n",
       "8  These are the best tips on the Nuk Bottles tha...       1.0   \n",
       "9  My 10 month old son is a great sleeper and has...       1.0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [my, son, is, now, 2, years, old, , we, bought...   \n",
       "1  [we, have, used, this, to, enclose, our, wood,...   \n",
       "2  [so, as, much, as, i, love, all, things, natur...   \n",
       "3  [this, was, a, beautiful, piece, and, fit, nic...   \n",
       "4  [there, s, nothing, wrong, with, the, cup, its...   \n",
       "5  [i, was, amazed, when, i, saw, how, cheap, thi...   \n",
       "6  [i, have, no, idea, why, i, even, thought, of,...   \n",
       "7  [i, gave, the, mats, to, my, daughter, s, pres...   \n",
       "8  [these, are, the, best, tips, on, the, nuk, bo...   \n",
       "9  [my, 10, month, old, son, is, a, great, sleepe...   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [son, 2, years, old, , bought, 7, months, , ha...   \n",
       "1  [used, enclose, wood, stove, protect, kids, , ...   \n",
       "2  [much, love, things, natural, , skeptical, pro...   \n",
       "3  [beautiful, piece, fit, nicely, bunk, beds, , ...   \n",
       "4  [nothing, wrong, cup, , love, cup, , make, mis...   \n",
       "5  [amazed, saw, cheap, bag, compared, others, ev...   \n",
       "6  [idea, even, thought, getting, , , exterior, p...   \n",
       "7  [gave, mats, daughter, preschool, gift, , kids...   \n",
       "8  [best, tips, nuk, bottles, get, teeth, start, ...   \n",
       "9  [10, month, old, son, great, sleeper, since, a...   \n",
       "\n",
       "                                               stems  \\\n",
       "0  [son, 2, year, old, , bought, 7, month, , hand...   \n",
       "1  [use, enclos, wood, stove, protect, kid, , wor...   \n",
       "2  [much, love, thing, natur, , skeptic, product,...   \n",
       "3  [beauti, piec, fit, nice, bunk, bed, , , easi,...   \n",
       "4  [noth, wrong, cup, , love, cup, , make, mistak...   \n",
       "5  [amaz, saw, cheap, bag, compar, other, even, o...   \n",
       "6  [idea, even, thought, get, , , exterior, packa...   \n",
       "7  [gave, mat, daughter, preschool, gift, , kid, ...   \n",
       "8  [best, tip, nuk, bottl, get, teeth, start, che...   \n",
       "9  [10, month, old, son, great, sleeper, sinc, ar...   \n",
       "\n",
       "                                              ngrams  \\\n",
       "0  [son 2 year, 2 year old, year old , old  bough...   \n",
       "1  [use enclos wood, enclos wood stove, wood stov...   \n",
       "2  [much love thing, love thing natur, thing natu...   \n",
       "3  [beauti piec fit, piec fit nice, fit nice bunk...   \n",
       "4  [noth wrong cup, wrong cup , cup  love,  love ...   \n",
       "5  [amaz saw cheap, saw cheap bag, cheap bag comp...   \n",
       "6  [idea even thought, even thought get, thought ...   \n",
       "7  [gave mat daughter, mat daughter preschool, da...   \n",
       "8  [best tip nuk, tip nuk bottl, nuk bottl get, b...   \n",
       "9  [10 month old, month old son, old son great, s...   \n",
       "\n",
       "                                                  tf  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (1.82692062624, 0.0, 3.22663271037, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  (0.0, 3.08723358449, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                     rawPrediction                probability  prediction  \n",
       "0  [-4044.31968499, 4044.31968499]                 [0.0, 1.0]         1.0  \n",
       "1  [-3164.92569261, 3164.92569261]                 [0.0, 1.0]         1.0  \n",
       "2  [-5341.67880727, 5341.67880727]                 [0.0, 1.0]         1.0  \n",
       "3    [-1222.1505214, 1222.1505214]                 [0.0, 1.0]         1.0  \n",
       "4  [1610.33450113, -1610.33450113]                 [1.0, 0.0]         0.0  \n",
       "5  [-992.717734987, 992.717734987]                 [0.0, 1.0]         1.0  \n",
       "6  [-837.094291579, 837.094291579]                 [0.0, 1.0]         1.0  \n",
       "7  [-677.727977688, 677.727977688]  [4.63958417669e-295, 1.0]         1.0  \n",
       "8  [-217.578766464, 217.578766464]   [3.21175452925e-95, 1.0]         1.0  \n",
       "9  [-6818.20425706, 6818.20425706]                 [0.0, 1.0]         1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.transform(test_data)\n",
    "\n",
    "pred.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Model Evaluation\n",
    "As in the original exercise, we want to use a custom metric for assessing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "class AccuracyClassificationEvaluator(Evaluator):\n",
    "    def __init__(self, predictionCol='prediction', labelCol='label'):\n",
    "        super(Evaluator,self).__init__()\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "    \n",
    "    def _evaluate(self, dataset):\n",
    "        num_total = dataset.count()\n",
    "        num_correct = dataset.filter(col(self.labelCol) == col(self.predictionCol)).count()\n",
    "        accuracy = float(num_correct) / num_total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Performance\n",
    "\n",
    "With the evaluator we can assess the performance of the prediction and easily compare it to a simple model which always predicts 'positive'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num positive reviews: 26740\n",
      "Num negative reviews: 5010\n"
     ]
    }
   ],
   "source": [
    "print(\"Num positive reviews: %d\" % pred.filter(pred.sentiment > 0.5).count())\n",
    "print(\"Num negative reviews: %d\" % pred.filter(pred.sentiment < 0.5).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 0.879780\n",
      "Baseline Accuracy = 0.842205\n"
     ]
    }
   ],
   "source": [
    "always_positive = pred.withColumn('prediction',lit(1.0))\n",
    "\n",
    "evaluator = AccuracyClassificationEvaluator(predictionCol='prediction', labelCol='sentiment')\n",
    "\n",
    "print(\"Model Accuracy = %f\" % evaluator.evaluate(pred))\n",
    "print(\"Baseline Accuracy = %f\" % evaluator.evaluate(always_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark 2.1 (Python 3.5)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
