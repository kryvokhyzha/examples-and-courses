{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Copy of extra_practice_Attention_basics_and_tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcqkcSoIzKl9"
      },
      "source": [
        "## Practice: Attention Basics\n",
        "Original notebook is provided by Udacity at [github](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/attention/Attention_Basics.ipynb).\n",
        "\n",
        "In this notebook, we look at how attention is implemented. We will focus on implementing attention in isolation from a larger model. That's because when implementing attention in a real-world model, a lot of the focus goes into piping the data and juggling the various vectors rather than the concepts of attention themselves.\n",
        "\n",
        "We will implement attention scoring as well as calculating an attention context vector.\n",
        "\n",
        "## Attention Scoring\n",
        "### Inputs to the scoring function\n",
        "Let's start by looking at the inputs we'll give to the scoring function. We will assume we're in the first step in the decoding phase. The first input to the scoring function is the hidden state of decoder (assuming a toy RNN with three hidden nodes -- not usable in real life, but easier to illustrate):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kju1ieizKl-"
      },
      "source": [
        "dec_hidden_state = [5,1,20]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTNxVBikzKmC"
      },
      "source": [
        "Let's visualize this vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNcPlzrWzKmD",
        "outputId": "a97c91be-43c3-446c-f76f-6724ba979f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Let's visualize our decoder hidden state\n",
        "plt.figure(figsize=(1.5, 4.5))\n",
        "sns.heatmap(np.transpose(np.matrix(dec_hidden_state)), annot=True, cmap=sns.light_palette(\"purple\", as_cmap=True), linewidths=1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5c8fb63c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 108x324 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw-50qs2zKmI"
      },
      "source": [
        "Our first scoring function will score a single annotation (encoder hidden state), which looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDG-_JsDzKmJ"
      },
      "source": [
        "annotation = [3,12,45] #e.g. Encoder hidden state"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCFsI0qezKmN",
        "outputId": "960daa6d-065a-4c13-be6c-aeb18340662c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "# Let's visualize the single annotation\n",
        "plt.figure(figsize=(1.5, 4.5))\n",
        "sns.heatmap(np.transpose(np.matrix(annotation)), annot=True, cmap=sns.light_palette(\"orange\", as_cmap=True), linewidths=1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5c5f84160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 108x324 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM00nFUVzKmR"
      },
      "source": [
        "### IMPLEMENT: Scoring a Single Annotation\n",
        "Let's calculate the dot product of a single annotation. NumPy's [dot()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) is a good candidate for this operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbzBLujvzKmR",
        "outputId": "5d61afa9-f3e8-4b5d-d2af-61b410c5a4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def single_dot_attention_score(dec_hidden_state, enc_hidden_state):\n",
        "    # TODO: return the dot product of the two vectors\n",
        "    return np.dot(dec_hidden_state, enc_hidden_state)\n",
        "    \n",
        "single_dot_attention_score(dec_hidden_state, annotation)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO3HpaJyzKmX"
      },
      "source": [
        "\n",
        "### Annotations Matrix\n",
        "Let's now look at scoring all the annotations at once. To do that, here's our annotation matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDp2-uB9zKmY"
      },
      "source": [
        "annotations = np.transpose([[3,12,45], [59,2,5], [1,43,5], [4,3,45.3]])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5p7uzqCzKmc"
      },
      "source": [
        "And it can be visualized like this (each column is a hidden state of an encoder time step):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_V0FgG9zKmd",
        "outputId": "39f90da3-acd2-4f42-9566-9af094c6ba54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Let's visualize our annotation (each column is an annotation)\n",
        "ax = sns.heatmap(annotations, annot=True, cmap=sns.light_palette(\"orange\", as_cmap=True), linewidths=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaY2hqp7zKmg"
      },
      "source": [
        "### IMPLEMENT: Scoring All Annotations at Once\n",
        "Let's calculate the scores of all the annotations in one step using matrix multiplication. Let's continue to us the dot scoring method\n",
        "\n",
        "<img src=\"https://github.com/girafe-ai/ml-mipt/blob/advanced_f20/week1_03_Machine_Translation_and_Attention/img/scoring_functions.png?raw=1\" />\n",
        "\n",
        "To do that, we'll have to transpose `dec_hidden_state` and [matrix multiply](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html) it with `annotations`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ07x-24zKmh",
        "outputId": "3b8011ba-7b5e-4830-b7cb-5018a28253bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def dot_attention_score(dec_hidden_state, annotations):\n",
        "    # TODO: return the product of dec_hidden_state transpose and enc_hidden_states\n",
        "    return np.transpose(dec_hidden_state) @ annotations\n",
        "    \n",
        "attention_weights_raw = dot_attention_score(dec_hidden_state, annotations)\n",
        "attention_weights_raw"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([927., 397., 148., 929.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbnHTu5zKmk"
      },
      "source": [
        "Looking at these scores, can you guess which of the four vectors will get the most attention from the decoder at this time step?\n",
        "\n",
        "## Softmax\n",
        "Now that we have our scores, let's apply softmax:\n",
        "<img src=\"https://github.com/girafe-ai/ml-mipt/blob/advanced_f20/week1_03_Machine_Translation_and_Attention/img/softmax.png?raw=1\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_kQIXAnzKml",
        "outputId": "00129788-84fd-4967-b279-d5b89da8cddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def softmax(x):\n",
        "    x = np.array(x, dtype=np.float128)\n",
        "    e_x = np.exp(x)\n",
        "    return e_x / e_x.sum(axis=0) \n",
        "\n",
        "attention_weights = softmax(attention_weights_raw)\n",
        "attention_weights"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.19202922e-001, 7.94715151e-232, 5.76614420e-340, 8.80797078e-001],\n",
              "      dtype=float128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDA9MTs8zKmo"
      },
      "source": [
        "Even when knowing which annotation will get the most focus, it's interesting to see how drastic softmax makes the end score become. The first and last annotation had the respective scores of 927 and 929. But after softmax, the attention they'll get is 0.12 and 0.88 respectively.\n",
        "\n",
        "# Applying the scores back on the annotations\n",
        "Now that we have our scores, let's multiply each annotation by its score to proceed closer to the attention context vector. This is the multiplication part of this formula (we'll tackle the summation part in the latter cells)\n",
        "\n",
        "<img src=\"https://github.com/girafe-ai/ml-mipt/blob/advanced_f20/week1_03_Machine_Translation_and_Attention/img/Context_vector.png?raw=1\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHfVKd52zKmp",
        "outputId": "e8447265-d3c0-4963-d3c2-32bd91c829c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def apply_attention_scores(attention_weights, annotations):\n",
        "    # TODO: Multiple the annotations by their weights\n",
        "    return attention_weights * annotations\n",
        "\n",
        "applied_attention = apply_attention_scores(attention_weights, annotations)\n",
        "applied_attention"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.57608766e-001, 4.68881939e-230, 5.76614420e-340,\n",
              "        3.52318831e+000],\n",
              "       [1.43043506e+000, 1.58943030e-231, 2.47944200e-338,\n",
              "        2.64239123e+000],\n",
              "       [5.36413149e+000, 3.97357575e-231, 2.88307210e-339,\n",
              "        3.99001076e+001]], dtype=float128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqUl6v-NzKms"
      },
      "source": [
        "Let's visualize how the context vector looks now that we've applied the attention scores back on it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y5p2p1szKmt",
        "outputId": "6a8d6bda-2b85-4deb-8db2-d60122672930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Let's visualize our annotations after applying attention to them\n",
        "ax = sns.heatmap(applied_attention, annot=True, cmap=sns.light_palette(\"orange\", as_cmap=True), linewidths=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZjw6rmpzKmw"
      },
      "source": [
        "Contrast this with the raw annotations visualized earlier in the notebook, and we can see that the second and third annotations (columns) have been nearly wiped out. The first annotation maintains some of its value, and the fourth annotation is the most pronounced.\n",
        "\n",
        "# Calculating the Attention Context Vector\n",
        "All that remains to produce our attention context vector now is to sum up the four columns to produce a single attention context vector\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1apfd_Q7zKmx",
        "outputId": "69f22489-ec55-4883-e1af-a1413ab0f286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def calculate_attention_vector(applied_attention):\n",
        "    return np.sum(applied_attention, axis=1)\n",
        "\n",
        "attention_vector = calculate_attention_vector(applied_attention)\n",
        "attention_vector"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.88079708,  4.0728263 , 45.26423912], dtype=float128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3jRSgEMnzKm1",
        "outputId": "f2fd3a6a-40a6-4311-e915-9d217fc923a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Let's visualize the attention context vector\n",
        "plt.figure(figsize=(1.5, 4.5))\n",
        "sns.heatmap(np.transpose(np.matrix(attention_vector)), annot=True, cmap=sns.light_palette(\"Blue\", as_cmap=True), linewidths=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5c5717358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 108x324 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOVDLq5DzKm4"
      },
      "source": [
        "Now that we have the context vector, we can concatenate it with the hidden state and pass it through a hidden layer to produce the the result of this decoding time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTOd64pIzKm4"
      },
      "source": [
        "### Your turn:\n",
        "Now implement the _general_ and _concat_ attention scores and check it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwm1QHhPzKm5"
      },
      "source": [
        "# Yeah, you need to initialize the matrix first (just use random, the main idea is the dimentionality)\n",
        "Wa = # <YOUR CODE HERE> \n",
        "def general_attention_score(dec_hidden_state, annotations, Wa):\n",
        "    # TODO: return the product of dec_hidden_state transpose and enc_hidden_states\n",
        "    return \n",
        "    \n",
        "attention_weights_raw = general_attention_score(dec_hidden_state, annotations, Wa)\n",
        "attention_weights_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4RoqDJ1zKm8"
      },
      "source": [
        "# Some post-processing like above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilh-YW8uzKnA"
      },
      "source": [
        "# And here you need to initialize both the vector v and the matrix Wa (\n",
        "# (again, random is fine)\n",
        "\n",
        "Wa = # <YOUR CODE HERE> \n",
        "va = # <YOUR CODE HERE> \n",
        "def concat_attention_score(dec_hidden_state, annotations, Wa, va):\n",
        "    # TODO: return the product of dec_hidden_state transpose and enc_hidden_states\n",
        "    return \n",
        "    \n",
        "attention_weights_raw = concat_attention_score(dec_hidden_state, annotations, Wa, va)\n",
        "attention_weights_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA1CvoMnzKnD"
      },
      "source": [
        "# And again some post-processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV2CMelxzKnG"
      },
      "source": [
        "## Part 2: Google Colab intro\n",
        "We roll back to the week03 practice: name generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uUjnl8azKnH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n3KeLq1zKnK"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMS2_YW0zKnN"
      },
      "source": [
        "start_token = \" \"\n",
        "\n",
        "def read_names(path_to_file):\n",
        "    global start_token\n",
        "    \n",
        "    with open(path_to_file) as f:\n",
        "        names = f.read()[:-1].split('\\n')\n",
        "        names = [start_token + line for line in names]\n",
        "        return names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBqDvbXrzKnQ"
      },
      "source": [
        "try:\n",
        "    names = read_names('../datasets/names_dataset/names')\n",
        "except FileNotFoundError:\n",
        "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/names_dataset/names -nc -O names\n",
        "    names = read_names('./names')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skrN88qJzKnT"
      },
      "source": [
        "try:\n",
        "    names_ru = read_names('../datasets/names_dataset/names_ru')\n",
        "except FileNotFoundError:\n",
        "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/names_dataset/names_ru -nc -O names_ru\n",
        "    names_ru = read_names('./names_ru')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dK41iztzKna"
      },
      "source": [
        "print ('n samples = ',len(names_ru))\n",
        "for idx in np.arange(0, len(names), 1000):\n",
        "    print(names[idx], names_ru[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoXEgCY9zKnf"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length =\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)),bins=25, label='en');\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names_ru)),bins=25, alpha=0.5, label='ru');\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vlC_iitzKni"
      },
      "source": [
        "all_tokens_set_en = set()\n",
        "for name in names:\n",
        "    all_tokens_set_en.update(set(name))\n",
        "\n",
        "\n",
        "tokens_en = list(all_tokens_set_en)# <list of all unique characters in the dataset>\n",
        "\n",
        "num_tokens_en = len(tokens_en)\n",
        "print ('num_tokens = ', num_tokens_en)\n",
        "\n",
        "assert 50 < num_tokens_en < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TfLzfhPzKnl"
      },
      "source": [
        "all_tokens_set_ru = set()\n",
        "for name in names_ru:\n",
        "    all_tokens_set_ru.update(set(name))\n",
        "\n",
        "\n",
        "tokens_ru = list(all_tokens_set_ru)# <list of all unique characters in the dataset>\n",
        "\n",
        "num_tokens_ru = len(tokens_ru)\n",
        "print ('num_tokens = ', num_tokens_ru)\n",
        "\n",
        "assert 50 < num_tokens_ru < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg0CsKE5zKno"
      },
      "source": [
        "token_to_id_en = {\n",
        "    token: idx for idx, token in enumerate(tokens_en)\n",
        "}\n",
        "\n",
        "token_to_id_ru = {\n",
        "    token: idx for idx, token in enumerate(tokens_ru)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8jS8KjBzKnr"
      },
      "source": [
        "assert len(tokens_ru) == len(token_to_id_ru), \"dictionaries must have same size\"\n",
        "\n",
        "for i in range(num_tokens_ru):\n",
        "    assert token_to_id_ru[tokens_ru[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "\n",
        "for i in range(num_tokens_en):\n",
        "    assert token_to_id_en[tokens_en[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "\n",
        "    \n",
        "print(\"Seems alright!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3cUrwbnzKnw"
      },
      "source": [
        "def to_matrix(names, token_to_id, max_len=None, pad=None, dtype='int32', batch_first=False):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "    pad = token_to_id[' ']\n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        line_ix = [token_to_id[c] for c in names[i]]\n",
        "        names_ix[i, :len(line_ix)] = line_ix\n",
        "        \n",
        "    if not batch_first: # convert [batch, time] into [time, batch]\n",
        "        names_ix = np.transpose(names_ix)\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCZ0Bg4ozKnz"
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5QvNPH8zKn1"
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens_en, emb_size=16, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.RNN(emb_size, rnn_num_units)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        assert isinstance(x.data, torch.LongTensor)\n",
        "        h_seq, _ = self.rnn(self.emb(x))\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "        return next_logp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMibQcTQzKn4"
      },
      "source": [
        "model = MyModel()\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.NLLLoss()\n",
        "history = []\n",
        "\n",
        "# the model applies over the whole sequence\n",
        "batch_ix = to_matrix(sample(names, 32), token_to_id_en, max_len=MAX_LENGTH)\n",
        "batch_ix = torch.LongTensor(batch_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw9jJ1sNzKn7"
      },
      "source": [
        "logp_seq = model(batch_ix)\n",
        "\n",
        "loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens_en),\n",
        "                 batch_ix[:, 1:].contiguous().view(-1))\n",
        "\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNQgEkO6zKn-"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LauUi_PrzKoD"
      },
      "source": [
        "writer.add_graph(model, batch_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3FEDcq7zKoF"
      },
      "source": [
        "MAX_LENGTH = 16\n",
        "\n",
        "for i in range(1000):\n",
        "    batch_ix = to_matrix(sample(names, 32), token_to_id_en, max_len=MAX_LENGTH)\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "    \n",
        "    logp_seq = model(batch_ix)\n",
        "    \n",
        "    loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens_en),\n",
        "                 batch_ix[:, 1:].contiguous().view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    \n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    # compute loss\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    # train with backprop\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    history.append(loss.data.numpy())\n",
        "    if (i+1)%100==0:\n",
        "        writer.add_scalar('train loss', history[-1], i)\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX-DGhxKzKoI"
      },
      "source": [
        "## More serious: char-level machine translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRZ-yHxozKoJ"
      },
      "source": [
        "Let's try to transliterate these names from English to Russian. So we need 2 models: encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Qw59XezKoJ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens_en, emb_size=16, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.RNN(emb_size, rnn_num_units)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        assert isinstance(x.data, torch.LongTensor)\n",
        "        h_seq, h_last = self.rnn(self.emb(x))\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "        return next_logp, h_last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1ovS_rxzKoM"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens_ru, emb_size=16, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.RNN(emb_size, rnn_num_units)\n",
        "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        \n",
        "    def forward(self, x, enc_last_state):\n",
        "        assert isinstance(x.data, torch.LongTensor)\n",
        "        h_seq, h_last = self.rnn(self.emb(x), enc_last_state)\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "        return next_logp, h_last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWBYEowazKoQ"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(self.__class__, self).__init__()\n",
        "        # YOUR CODE HERE\n",
        "    \n",
        "    def forward(self, src, trg):\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        return logp_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OHazlmDzKoT"
      },
      "source": [
        "nmt_model = Seq2Seq()\n",
        "opt = torch.optim.Adam(nmt_model.parameters())\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJG58BezKoW"
      },
      "source": [
        "# example\n",
        "indices = np.random.choice(np.arange(len(names)), size=32)\n",
        "batch_en = to_matrix(np.array(names)[indices], token_to_id=token_to_id_en, max_len=MAX_LENGTH)\n",
        "input_tensor = torch.from_numpy(batch_en).type(torch.int64)\n",
        "\n",
        "batch_ru = to_matrix(np.array(names_ru)[indices], token_to_id=token_to_id_ru, max_len=MAX_LENGTH)\n",
        "target_tensor = torch.from_numpy(batch_ru).type(torch.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouLeaUxGzKob"
      },
      "source": [
        "out = nmt_model(input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDlWMmmOzKog"
      },
      "source": [
        "idx_to_token_en = {idx: token for token, idx in token_to_id_en.items()}\n",
        "idx_to_token_ru = {idx: token for token, idx in token_to_id_ru.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4qBitjWzKok"
      },
      "source": [
        "a = out.argmax(dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hYiZgpJzKon"
      },
      "source": [
        "# Train your model here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebgYCzpwzKoq"
      },
      "source": [
        "Let's take a look at the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQBBLsjwzKor"
      },
      "source": [
        "def get_example(idx):\n",
        "    translated = ''.join([idx_to_token_ru[x] for x in a[:, idx].numpy()])\n",
        "    original = ''.join([idx_to_token_en[x] for x in input_tensor[:, idx].numpy()])\n",
        "    print(original, translated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPqL8kkFzKou"
      },
      "source": [
        "get_example(9)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}